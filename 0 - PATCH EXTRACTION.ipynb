{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from plotutils import plot_images_as_grid\n",
    "\n",
    "from generate_datasets import create_cell_and_no_cell_patches, create_dataset_from_patches\n",
    "\n",
    "import image_processing\n",
    "import video_session\n",
    "import patch_extraction\n",
    "\n",
    "from cnnlearning import CNN\n",
    "\n",
    "from learning_utils import ImageDataset\n",
    "from classificationutils import create_probability_map\n",
    "\n",
    "from cnnlearning import TrainingTracker, train\n",
    "import os\n",
    "import collections\n",
    "\n",
    "import scipy\n",
    "import skimage\n",
    "from skimage.morphology import binary_dilation as bd\n",
    "from skimage.exposure import equalize_adapthist\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import copy\n",
    "\n",
    "training_video_sessions = video_session.get_video_sessions(marked=True, validation=False)\n",
    "validation_video_sessions = video_session.get_video_sessions(marked=True, validation=True)\n",
    "\n",
    "# video_sessions = [vs for vs in video_sessions if 'shared-videos' in vs.video_file]\n",
    "print('training videos')\n",
    "display([vs.video_file for vs in training_video_sessions])\n",
    "\n",
    "print('validation videos')\n",
    "display([vs.video_file for vs in validation_video_sessions])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patch extraction helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = training_video_sessions[1]\n",
    "points = vs.cell_positions[0]\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(points[:, 0], points[:, 1])\n",
    "x, y = patch_extraction.get_parallel_points(points, 21)\n",
    "plt.scatter(x, y)\n",
    "plt.title('parallel points')\n",
    "\n",
    "vs = training_video_sessions[5]\n",
    "points = vs.cell_positions[0]\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(points[:, 0], points[:, 1])\n",
    "x, y = patch_extraction.get_perpendicular_points(points, 9)\n",
    "plt.scatter(x, y)\n",
    "plt.title('perpendicular points')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perpendicular search negative patch extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from video_session import get_video_sessions\n",
    "from patch_extraction import SessionPatchExtractor\n",
    "from generate_datasets import create_cell_and_no_cell_patches\n",
    "from patch_extraction import SessionPatchExtractor as PE\n",
    "from plotutils import plot_images_as_grid\n",
    "\n",
    "video_sessions = get_video_sessions(marked=True, registered=True, validation=True)\n",
    "vs = video_sessions[0]\n",
    "\n",
    "negative_extraction_mode = patch_extraction.NegativeExtractionMode.PERPENDICULAR\n",
    "patch_extractor = patch_extraction.SessionPatchExtractor(\n",
    "    vs, \n",
    "    patch_size=21, \n",
    "    n_negatives_per_positive=32,\n",
    "    limit_to_vessel_mask=False, \n",
    "    negative_extraction_mode = negative_extraction_mode,\n",
    "    negative_extraction_radius=32, # Extraction radius here is the length of the line between the cell positions\n",
    "    v=True,\n",
    "    extraction_mode=PE.ALL_MODE\n",
    ")\n",
    "\n",
    "print(patch_extractor.cell_patches_oa790.shape)\n",
    "print(patch_extractor.non_cell_patches_oa790.shape)\n",
    "plot_images_as_grid(patch_extractor.cell_patches_oa790[:10])\n",
    "plot_images_as_grid(patch_extractor.marked_cell_patches_oa790[:10])\n",
    "\n",
    "plot_images_as_grid(patch_extractor.non_cell_patches_oa790[:10])\n",
    "plot_images_as_grid(patch_extractor.marked_non_cell_patches_oa790[:10])\n",
    "patch_extractor.visualize_patch_extraction(linewidth=2, s=100, frame_idx=0, figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limit to vessel mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from video_session import get_video_sessions\n",
    "from patch_extraction import SessionPatchExtractor\n",
    "from generate_datasets import create_cell_and_no_cell_patches\n",
    "from patch_extraction import SessionPatchExtractor as PE\n",
    "from plotutils import plot_images_as_grid\n",
    "\n",
    "video_sessions = get_video_sessions(marked=True, registered=True, validation=True)\n",
    "vs = video_sessions[0]\n",
    "\n",
    "negative_extraction_mode = patch_extraction.NegativeExtractionMode.PERPENDICULAR\n",
    "patch_extractor = patch_extraction.SessionPatchExtractor(\n",
    "    vs, \n",
    "    patch_size=25, \n",
    "    n_negatives_per_positive=32,\n",
    "    limit_to_vessel_mask=True, \n",
    "    negative_extraction_mode = negative_extraction_mode,\n",
    "    negative_extraction_radius=32, # Extraction radius here is the length of the line between the cell positions\n",
    "    v=True,\n",
    "    extraction_mode=PE.ALL_MODE\n",
    ")\n",
    "\n",
    "print(patch_extractor.cell_patches_oa790.shape)\n",
    "print(patch_extractor.non_cell_patches_oa790.shape)\n",
    "plot_images_as_grid(patch_extractor.cell_patches_oa790[:10])\n",
    "plot_images_as_grid(patch_extractor.marked_cell_patches_oa790[:10])\n",
    "\n",
    "plot_images_as_grid(patch_extractor.non_cell_patches_oa790[:10])\n",
    "plot_images_as_grid(patch_extractor.marked_non_cell_patches_oa790[:10])\n",
    "patch_extractor.visualize_patch_extraction(linewidth=2, s=100, frame_idx=0, figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "penguins = sns.load_dataset(\"penguins\")\n",
    "sns.displot(penguins, x=\"flipper_length_mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = patch_extractor.with_session(video_session.get_video_sessions(validation=False)[0]).cell_patches_oa790.flatten().mean()\n",
    "std =  patch_extractor.with_session(video_session.get_video_sessions(validation=False)[0]).cell_patches_oa790.flatten().std()\n",
    "\n",
    "# newImage1 = (image1-mean1)*std2/std1 + mean2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_target_distribution(values, target_mean, target_std):\n",
    "    # https://www.mathworks.com/matlabcentral/answers/236286-image-normalization-same-mean-and-same-std\n",
    "    return (values - values.mean()) * target_std / values.std() + target_mean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_session.get_video_sessions(validation=False)[0].frames_oa790[0].min(), video_session.get_video_sessions(validation=False)[0].frames_oa790[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data\n",
    "from skimage import exposure\n",
    "from skimage.exposure import match_histograms\n",
    "\n",
    "reference = data.coffee()\n",
    "image = data.chelsea()\n",
    "\n",
    "matched = match_histograms(image, reference, multichannel=True)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(8, 3),\n",
    "                                    sharex=True, sharey=True)\n",
    "for aa in (ax1, ax2, ax3):\n",
    "    aa.set_axis_off()\n",
    "plt.rcParams['font.size'] = 34\n",
    "ax1.imshow(image)\n",
    "ax1.set_title('Source', fontdict={'fontsize' :34})\n",
    "ax2.imshow(reference)\n",
    "ax2.set_title('Reference', fontdict={'fontsize' :34})\n",
    "ax3.imshow(matched)\n",
    "ax3.set_title('Matched', fontdict={'fontsize' :34})\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(8, 3),\n",
    "                                    sharex=True, sharey=True)\n",
    "for aa in (ax1, ax2, ax3):\n",
    "    aa.set_axis_off()\n",
    "plt.rcParams['font.size'] = 34\n",
    "sns.histplot(image.flatten(), ax=ax1, color='r')\n",
    "ax1.set_title('Source', fontdict={'fontsize' :34})\n",
    "sns.histplot(reference.flatten(), ax=ax2, color='g')\n",
    "ax2.set_title('Reference', fontdict={'fontsize' :34})\n",
    "sns.histplot(matched.flatten(), ax=ax3, color='b')\n",
    "ax3.set_title('Matched', fontdict={'fontsize' :34})\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 35\n",
    "plt.subplot(1, 2, 1)\n",
    "im1 = video_session.get_video_sessions(validation=False)[0].frames_oa790[0]\n",
    "plt.imshow(im1, cmap='gray')\n",
    "plt.subplot(1, 2, 2)\n",
    "im2 = video_session.get_video_sessions(validation=False)[1].frames_oa790[0]\n",
    "plt.imshow(im2, cmap='gray')\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1, 2, 1)\n",
    "im1 = video_session.get_video_sessions(validation=False)[0].frames_oa790[0]\n",
    "sns.histplot(im1.flatten(), color='r')\n",
    "sns.histplot(im2.flatten(), color='g')\n",
    "matched = match_histograms(im1, im2, multichannel=False)\n",
    "sns.histplot(matched.flatten(), color='b')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "im2 = video_session.get_video_sessions(validation=False)[1].frames_oa790[0]\n",
    "sns.histplot(im2.flatten(), color='g')\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1, 2, 1)\n",
    "im1 = video_session.get_video_sessions(validation=False)[0].frames_oa790[0]\n",
    "plt.imshow(im1, cmap='gray')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "im2 = video_session.get_video_sessions(validation=False)[1].frames_oa790[0]\n",
    "matched = match_histograms(im1, im2, multichannel=False)\n",
    "plt.imshow(matched, cmap='gray')\n",
    "print(matched.dtype, im1.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', \"tab:brown\", 'tab:pink', \"tab:olive\"]\n",
    "fig, ax = plt.subplots(1, 2, figsize=(30, 20))\n",
    "target_dis\n",
    "for i, vs in enumerate(video_session.get_video_sessions(validation=False)):\n",
    "    values = patch_extractor.with_session(vs).cell_patches_oa790.flatten() \n",
    "    neg_values = patch_extractor.with_session(vs).non_cell_patches_oa790.flatten()\n",
    "    sns.histplot(values, ax=ax[0], color=colors[i])\n",
    "    sns.histplot(neg_values, ax=ax[1], color=colors[i])\n",
    "\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', \"tab:brown\", 'tab:pink', \"tab:olive\"]\n",
    "fig, ax = plt.subplots(1, 2, figsize=(30, 20))\n",
    "for i, vs in enumerate(video_session.get_video_sessions(validation=False)):\n",
    "    values = patch_extractor.with_session(vs).cell_patches_oa790.flatten() \n",
    "    neg_values = patch_extractor.with_session(vs).non_cell_patches_oa790.flatten()\n",
    "    sns.histplot(values, ax=ax[0], color=colors[i])\n",
    "    sns.histplot(neg_values, ax=ax[1], color=colors[i])\n",
    "\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_processing import SessionPreprocessor\n",
    "\n",
    "vs = video_session.get_video_sessions(validation=False)[0]\n",
    "\n",
    "sp = SessionPreprocessor(vs)\n",
    "reference = video_session.get_video_sessions(validation=False)[1].frames_oa790[0]\n",
    "\n",
    "# sp.with_session(vs).with_preprocess([lambda x: match_histograms(x, reference), lambda x: x / 255]).map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "colors = ['r', 'g', 'b']\n",
    "for i in range(3):\n",
    "    sns.histplot(vs.frames_oa790[i].flatten(), ax=ax, color=colors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "colors = ['r', 'g', 'b']\n",
    "for i in range(3):\n",
    "    sns.histplot(vs.frames_oa790[i].flatten(), ax=ax, color=colors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(vs.frames_oa790[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(vs.frames_oa790[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', \"tab:brown\", 'tab:pink', \"tab:olive\"]\n",
    "fig, ax = plt.subplots(1, 2, figsize=(30, 20))\n",
    "for i, vs in enumerate(video_session.get_video_sessions(validation=False)):\n",
    "    values = patch_extractor.with_session(vs).cell_patches_oa790.flatten() \n",
    "    neg_values = patch_extractor.with_session(vs).non_cell_patches_oa790.flatten()\n",
    "    sns.histplot(values, ax=ax[0], color=colors[i])\n",
    "    sns.histplot(neg_values, ax=ax[1], color=colors[i])\n",
    "\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', \"tab:brown\", 'tab:pink', \"tab:olive\"]\n",
    "fig, ax = plt.subplots(1, 2, figsize=(30, 20))\n",
    "for i, vs in enumerate(video_session.get_video_sessions(validation=False)):\n",
    "    values = patch_extractor.with_session(vs).cell_patches_oa790.flatten() \n",
    "    neg_values = patch_extractor.with_session(vs).non_cell_patches_oa790.flatten()\n",
    "    sns.histplot(match_target_distribution(values, mean, std), ax=ax[0], color=colors[i])\n",
    "    sns.histplot(match_target_distribution(neg_values, mean, std), ax=ax[1], color=colors[i])\n",
    "\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(patch_extractor.cell_patches_oa790.flatten())\n",
    "sns.displot(patch_extractor.cell_patches_oa790.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Circle search negative patch extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from video_session import get_video_sessions\n",
    "from patch_extraction import SessionPatchExtractor\n",
    "from generate_datasets import create_cell_and_no_cell_patches\n",
    "from patch_extraction import SessionPatchExtractor as PE\n",
    "from plotutils import plot_images_as_grid\n",
    "\n",
    "video_sessions = get_video_sessions(marked=True, registered=True, validation=True)\n",
    "vs = video_sessions[0]\n",
    "\n",
    "patch_extractor = SessionPatchExtractor(\n",
    "    vs, \n",
    "    patch_size=21, \n",
    "    n_negatives_per_positive=32,\n",
    "    limit_to_vessel_mask=False, \n",
    "    extraction_mode=PE.ALL_MODE)\n",
    "\n",
    "print(patch_extractor.cell_patches_oa790.shape)\n",
    "print(patch_extractor.non_cell_patches_oa790.shape)\n",
    "\n",
    "plot_images_as_grid(patch_extractor.cell_patches_oa790[:10])\n",
    "plot_images_as_grid(patch_extractor.marked_cell_patches_oa790[:10])\n",
    "\n",
    "plot_images_as_grid(patch_extractor.non_cell_patches_oa790[:10])\n",
    "plot_images_as_grid(patch_extractor.marked_non_cell_patches_oa790[:10])\n",
    "patch_extractor.visualize_patch_extraction(linewidth=2, s=100, frame_idx=0, figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limit to vessel mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from video_session import get_video_sessions\n",
    "from patch_extraction import SessionPatchExtractor\n",
    "from generate_datasets import create_cell_and_no_cell_patches\n",
    "from patch_extraction import SessionPatchExtractor as PE\n",
    "from plotutils import plot_images_as_grid\n",
    "\n",
    "video_sessions = get_video_sessions(marked=True, registered=True, validation=True)\n",
    "vs = video_sessions[0]\n",
    "\n",
    "patch_extractor = SessionPatchExtractor(\n",
    "    vs, \n",
    "    patch_size=21, \n",
    "    n_negatives_per_positive=32,\n",
    "    limit_to_vessel_mask=True, \n",
    "    extraction_mode=PE.ALL_MODE)\n",
    "\n",
    "print(patch_extractor.cell_patches_oa790.shape)\n",
    "print(patch_extractor.non_cell_patches_oa790.shape)\n",
    "\n",
    "plot_images_as_grid(patch_extractor.cell_patches_oa790[:10])\n",
    "plot_images_as_grid(patch_extractor.marked_cell_patches_oa790[:10])\n",
    "\n",
    "plot_images_as_grid(patch_extractor.non_cell_patches_oa790[:10])\n",
    "plot_images_as_grid(patch_extractor.marked_non_cell_patches_oa790[:10])\n",
    "patch_extractor.visualize_patch_extraction(linewidth=2, s=100, frame_idx=0, figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal patches\n",
    "\n",
    "Temporal patches include the patches from the same positions from the next and previous frames of the oa790 channel.\n",
    "\n",
    "All the spatial patch extraction methods described earlier apply here as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from video_session import get_video_sessions\n",
    "from patch_extraction import SessionPatchExtractor\n",
    "from plotutils import plot_images_as_grid\n",
    "\n",
    "video_sessions = get_video_sessions(marked=True, validation=True)\n",
    "vs = video_sessions[0]\n",
    "\n",
    "patch_extractor = SessionPatchExtractor(vs, patch_size=21, temporal_width=1, n_negatives_per_positive=7)\n",
    "\n",
    "plot_images_as_grid(patch_extractor.temporal_cell_patches_oa790[:10], title='Temporal cell patches temporal width 1')\n",
    "plot_images_as_grid(patch_extractor.temporal_marked_cell_patches_oa790[:10])\n",
    "\n",
    "plot_images_as_grid(patch_extractor.temporal_non_cell_patches_oa790[:10], title='Temporal non cell patches temporal width 1')\n",
    "plot_images_as_grid(patch_extractor.temporal_marked_non_cell_patches_oa790[:10])\n",
    "\n",
    "# A higher temporal width will give patches with more channells\n",
    "patch_extractor.temporal_width = 1\n",
    "print(f'Temporal patches shape with temporal width = 1: {patch_extractor.temporal_cell_patches_oa790.shape}')\n",
    "patch_extractor.temporal_width = 4\n",
    "print(f'Temporal patches shape with temporal width = 4: {patch_extractor.temporal_cell_patches_oa790.shape}')\n",
    "patch_extractor.temporal_width = 5\n",
    "print(f'Temporal patches shape with temporal width = 5: {patch_extractor.temporal_cell_patches_oa790.shape}')\n",
    "patch_extractor.temporal_width = 6\n",
    "print(f'Temporal patches shape with temporal width = 6: {patch_extractor.temporal_cell_patches_oa790.shape}')\n",
    "print(f\"As temporal window becomes bigger notice that there are less patches becasue we can't use some frames at the begining and the end\")\n",
    "patch_extractor.temporal_width = 1\n",
    "patch_extractor.visualize_temporal_patch_extraction(figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixed channel patches\n",
    " \n",
    "Mixed channel patches give patches with 3 channels, the first channel is confocal video patch, second channel is from the oa780 channel,\n",
    "third channel is from the oa850 channel.\n",
    "\n",
    "The confocal video and the oa790 channel have the capillaries at the same position. The oa850 video has a vertical displacement, the oa850 frames are registered before extracting the patches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Registration process\n",
    "\n",
    "The vessel mask for the 790nm and 850nm video is created and then registered vertically by maximising Dice's coefficient\n",
    "which is a similarity measure usually used to evaluate segmenation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from video_session import get_video_sessions\n",
    "from patch_extraction import SessionPatchExtractor\n",
    "from plotutils import plot_images_as_grid\n",
    "\n",
    "video_sessions = get_video_sessions(marked=True, registered=True)\n",
    "vs = video_sessions[1]\n",
    "\n",
    "vs.visualize_registration()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_extractor = SessionPatchExtractor(vs, patch_size=21)\n",
    "\n",
    "plot_images_as_grid(patch_extractor.mixed_channel_cell_patches[:10])\n",
    "plot_images_as_grid(patch_extractor.mixed_channel_marked_cell_patches[:10])\n",
    "\n",
    "plot_images_as_grid(patch_extractor.mixed_channel_non_cell_patches[:10])\n",
    "plot_images_as_grid(patch_extractor.mixed_channel_marked_non_cell_patches[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Showing the patches for each channel\n",
    "\n",
    "The first image is the patches extracted from the confocal video.\n",
    "Second is the patches extracted from the 790nm video.\n",
    "Third is the patches extracted from the 850nm video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 3, figsize=(150, 150))\n",
    "for i, ax in enumerate(axes):\n",
    "    patch_extractor.visualize_mixed_channel_patch_extraction(frame_idx=20, channel=i, ax=axes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
