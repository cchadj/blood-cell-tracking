{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from cnnlearning import *\n",
    "from learningutils import *\n",
    "from patchextraction import *\n",
    "from imageprosessing import *\n",
    "from nearest_neighbors import *\n",
    "from evaluation import *\n",
    "from classificationutils import *\n",
    "from sharedvariables import *\n",
    "from vesseldetection import *\n",
    "from generate_datasets import *\n",
    "from plotutils import no_ticks, plot_images_as_grid\n",
    "from guitools import CvRoipolySelector, CvPointSelector\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Jupyter Notebook settings\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "%autosave 20\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Imports for data analysis\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_rows', 2500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 2000)\n",
    "pd.set_option('display.width', 2000)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "# size=25\n",
    "size=10\n",
    "params = {'legend.fontsize': 'large',\n",
    "          'figure.figsize': (20,8),\n",
    "          'axes.labelsize': size,\n",
    "          'axes.titlesize': size,\n",
    "          'xtick.labelsize': size*0.75,\n",
    "          'ytick.labelsize': size*0.75,\n",
    "          'axes.titlepad': 25}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "report_images_folder = os.path.join(\n",
    "    '..', '..', 'thesis-report', 'images', 'channel_matching'\n",
    ")\n",
    "pathlib.Path(report_images_folder).mkdir(exist_ok=True, parents=False)\n",
    "\n",
    "video_sessions = get_video_sessions(marked=True, validation=False)\n",
    "\n",
    "[vs.load_vessel_masks() for vs in video_sessions]\n",
    "[vs.basename for vs in video_sessions], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemplateMatcher(object):\n",
    "    def __init__(self, im1=None, im2=None, method=cv2.TM_CCOEFF_NORMED):\n",
    "        template_matching_methods = [cv2.TM_CCOEFF, cv2.TM_CCOEFF_NORMED, cv2.TM_CCORR,\n",
    "                                     cv2.TM_CCORR_NORMED, cv2.TM_SQDIFF,  cv2.TM_SQDIFF_NORMED]\n",
    "        assert method in template_matching_methods\n",
    "        \n",
    "        self.method = method\n",
    "        \n",
    "        self.im1 = im1\n",
    "        self.im2 = im2\n",
    "        \n",
    "        self.cx, self.cy = None, None\n",
    "        self.dx, self.dy = None, None\n",
    "        self.correlation_image = None\n",
    "        self.image = None\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def match(self):\n",
    "        h, w = self.im1.shape\n",
    "        centre_row, centre_col = int(h / 2), int(w / 2)\n",
    "        template = self.im1[centre_row - 11:centre_row + 11,\n",
    "                            centre_col - 11:centre_col + 11]\n",
    "        self.template = template\n",
    "        \n",
    "        template = np.float32(self.template)\n",
    "        \n",
    "        image = np.float32(self.im2)\n",
    "        im_h, im_w = image.shape\n",
    "        template_h, template_w = template.shape\n",
    "        \n",
    "        correlation_image = cv2.matchTemplate(image, template, self.method)\n",
    "        self.correlation_image = correlation_image\n",
    "        \n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(correlation_image)\n",
    "        \n",
    "        # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
    "        if self.method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "            top_left = min_loc\n",
    "        else:\n",
    "            top_left = max_loc\n",
    "\n",
    "        self.cx, self.cy  = (np.floor(top_left[0] + template_w / 2), np.floor(top_left[1] + template_h / 2))\n",
    "        self.dx, self.dy = self.cx - (im_w - 1) / 2, self.cy - (im_h - 1) /2\n",
    "        \n",
    "        return self.cx, self.cy\n",
    "    \n",
    "    def visualize_matching(self, figsize=(15, 10), savename='', s=155,fontsize=10, linewidth=4.3):\n",
    "        import matplotlib.patches\n",
    "        from plotutils import savefig_tight\n",
    "        \n",
    "        im_h, im_w = self.im1.shape\n",
    "        mid_x, mid_y = int((im_w - 1) / 2), int((im_h - 1) /2) \n",
    "        \n",
    "        # template image\n",
    "        _, axes = plt.subplots(1, 3, figsize=figsize)\n",
    "        no_ticks(axes)\n",
    "        axes[0].imshow(self.template)\n",
    "        \n",
    "        \n",
    "        # image 1 with template square at middle\n",
    "        axes[1].imshow(self.im1)\n",
    "        if savename:\n",
    "            savefig_tight(f'{savename}_template.png')\n",
    "            \n",
    "        rect = matplotlib.patches.Rectangle((mid_x - 11, mid_y -11) , 21, 21, linewidth=7.5, edgecolor='r', facecolor='none')\n",
    "        axes[1].add_patch(rect)\n",
    "        if savename:\n",
    "            savefig_tight(f'{savename}_im1.png')\n",
    "            \n",
    "        # image 2 with displacement\n",
    "        axes[2].imshow(self.im2)\n",
    "        axes[2].scatter(mid_x, mid_y)\n",
    "        assert [mid_x + self.dx, mid_y + self.dy] == [self.cx, self.cy]\n",
    "        axes[2].scatter(self.cx, self.cy, s=s)\n",
    "\n",
    "        axes[2].plot([mid_x,    self.cx],         [mid_y,    self.cy], 'b', linestyle='--', linewidth=linewidth, marker='', label='displacment')\n",
    "        axes[2].plot([mid_x,    mid_x + self.dx], [mid_y,    mid_y],   'r', linestyle='--', linewidth=linewidth, marker='', label='dx')\n",
    "        axes[2].plot([mid_x + self.dx,    mid_x + self.dx],           [mid_y,    mid_y + self.dy], 'y', linewidth=linewidth, linestyle='--', marker='', label='dy')\n",
    "        axes[2].legend(prop={'size': fontsize})\n",
    "        if savename:\n",
    "            savefig_tight(f'{savename}_im2.png')\n",
    "        \n",
    "class FeatureMatcher(object):\n",
    "    def __init__(self, im1, im2):\n",
    "        self.im1 = im1\n",
    "        self.im2 = im2\n",
    "        \n",
    "        im1_x, im1_y = None, None\n",
    "        im2_x, im2_y = None, None\n",
    "        self.dx, self.dy = None, None\n",
    "\n",
    "    def match(self):\n",
    "        im1 = self.im1\n",
    "        im2 = self.im2\n",
    "        \n",
    "        if im1.dtype in [np.float, np.float16, np.float32, np.float64]:\n",
    "            im1 = np.uint8(im1 * 255)\n",
    "        \n",
    "        if im2.dtype in [np.float, np.float16, np.float32, np.float64]:\n",
    "            im2 = np.uint8(im2 * 255)\n",
    "            \n",
    "        for i in range(400, 0, -10):\n",
    "            # Initiate feature detector\n",
    "            surf = cv2.xfeatures2d.SURF_create(i)\n",
    "\n",
    "            # find the keypoints and descriptors with surf\n",
    "            kp1, des1 = surf.detectAndCompute(im1, None)\n",
    "            kp2, des2 = surf.detectAndCompute(im2, None)\n",
    "\n",
    "            if des1 is None or des2 is None or len(kp1) is 0 or len(kp2) is 0:\n",
    "                continue\n",
    "\n",
    "            # create BFMatcher object\n",
    "            bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "            # Match descriptors.\n",
    "            matches = bf.match(des1, des2)\n",
    "\n",
    "            if len(matches) is 0:\n",
    "                continue\n",
    "            # Sort them in the order of their distance.\n",
    "            matches = sorted(matches, key = lambda x:x.distance)\n",
    "            # Draw first match\n",
    "            match = matches[0]\n",
    "            img1_idx = match.queryIdx\n",
    "            img2_idx = match.trainIdx\n",
    "\n",
    "            self.kp1 = kp1\n",
    "            self.kp2 = kp2\n",
    "            self.matches = matches\n",
    "            \n",
    "            # x - columns\n",
    "            # y - rows\n",
    "            # Get the coordinates\n",
    "            self.im1_x, self.im1_y = kp1[img1_idx].pt\n",
    "            self.im2_x, self.im2_y = kp2[img2_idx].pt\n",
    "            \n",
    "            self.dx, self.dy = self.im2_x -  self.im1_x, self.im2_y - self.im1_y\n",
    "            return self.im2_x, self.im2_y\n",
    "        \n",
    "    def visualize_matching(self, figsize=(15, 10), linewidth=2.3, savefile=''):\n",
    "        from plotutils import savefig_tight\n",
    "        \n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(self.im1)\n",
    "        no_ticks()\n",
    "        plt.scatter(self.im1_x, self.im1_y)\n",
    "        ax1 = plt.gca()\n",
    "        \n",
    "        plt.subplot(122)\n",
    "        plt.imshow(self.im2)\n",
    "        no_ticks()\n",
    "        plt.scatter(self.im2_x, self.im2_y)\n",
    "        ax2 = plt.gca()\n",
    "\n",
    "        coordsA = \"data\"\n",
    "        coordsB = \"data\"\n",
    "        con = matplotlib.patches.ConnectionPatch(xyA=(self.im1_x, self.im1_y), xyB=(self.im2_x, self.im2_y), color='g',\n",
    "                                                 coordsA=coordsA, coordsB=coordsB, mutation_scale=15, linewidth=3.5,\n",
    "                                                 axesA=ax1, axesB=ax2, arrowstyle=\"->\", shrinkB=5, shrinkA=5)\n",
    "        ax2.add_artist(con)\n",
    "\n",
    "        \n",
    "        mid_x = self.im1_x\n",
    "        mid_y = self.im1_y\n",
    "        plt.plot([mid_x,    self.im2_x],         [mid_y,    self.im2_y], 'b', linestyle='--', linewidth=linewidth, marker='', label='displacment')\n",
    "        plt.plot([mid_x,    mid_x + self.dx], [mid_y,    mid_y],   'r', linestyle='--', linewidth=linewidth, marker='', label='dx')\n",
    "        plt.plot([mid_x + self.dx,    mid_x + self.dx],           [mid_y,    mid_y + self.dy], 'y', linewidth=linewidth, linestyle='--', marker='', label='dy')\n",
    "        plt.legend()\n",
    "\n",
    "        if savefile:\n",
    "            savefig_tight(f'{savefile}_feature_matching.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_average_images(video_session,\n",
    "                          frame_idx=0, \n",
    "                          mask=None,\n",
    "                          patch_size=51,\n",
    "                          sigma=1,\n",
    "                          visualise=False,\n",
    "                          savefile=''):\n",
    "    from skimage.exposure import equalize_adapthist\n",
    "    from imageprosessing import equalize_adapt_hist_masked\n",
    "    from skimage.filters import gaussian\n",
    "    \n",
    "    vs = video_session\n",
    "    if visualise:\n",
    "        vs.load_vessel_masks()\n",
    "        vs.visualize_registration()\n",
    "\n",
    "    #### #### #### #### #### #### #### #### #### #### \n",
    "    from plotutils import savefig_tight\n",
    "    \n",
    "    # cv2.imshow(window, frame_OA790)\n",
    "    registered_frame_oa850_clone = vs.registered_frames_oa850[frame_idx].copy()\n",
    "    registered_frame_oa850_clone = registered_frame_oa850_clone[..., np.newaxis]\n",
    "    registered_frame_oa850_clone = np.concatenate((registered_frame_oa850_clone, registered_frame_oa850_clone, registered_frame_oa850_clone), axis=-1)\n",
    "    \n",
    "    frame_oa790 = vs.frames_oa790[frame_idx]\n",
    "    \n",
    "    if mask is None:\n",
    "        window = 'Please Select a straight Segment with a lot of positions'\n",
    "\n",
    "        roipoly_selector = CvRoipolySelector(window, registered_frame_oa850_clone)\n",
    "        roipoly_selector.activate()\n",
    "\n",
    "        plt.rcParams['image.cmap'] = 'gray'\n",
    "        plt.rcParams['axes.titlesize'] = 30\n",
    "        plt.rcParams['figure.titlesize'] = 30\n",
    "\n",
    "        plt.figure(figsize=(30, 20))\n",
    "        plt.imshow(roipoly_selector.modified_image)\n",
    "        if savefile:\n",
    "            savefig_tight(f'{savefile}_selection.png')\n",
    "    \n",
    "        mask = roipoly_selector.mask.copy()\n",
    "        \n",
    "    if visualise:\n",
    "        plt.figure(figsize=(30, 20))\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(frame_oa790 * mask * vs.registered_mask_frames_oa850[frame_idx])\n",
    "        no_ticks()\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(vs.registered_frames_oa850[frame_idx] * mask * vs.registered_mask_frames_oa850[frame_idx])\n",
    "        no_ticks()\n",
    "        if savefile:\n",
    "            savefig_tight(f'{savefile}_selected_segment.png')\n",
    "\n",
    "    frame_oa790 = vs.frames_oa790[frame_idx]\n",
    "    registered_frame_oa850 = vs.registered_frames_oa850[frame_idx]\n",
    "    \n",
    "    frame_cell_positions = vs.cell_positions[frame_idx]\n",
    "    frame_cell_positions = np.delete(frame_cell_positions, np.where(~mask[frame_cell_positions[:, 1], frame_cell_positions[:, 0]])[0], axis=0)\n",
    "    \n",
    "    cell_patches_oa790 = extract_patches_at_positions(frame_oa790,            frame_cell_positions, mask=mask, patch_size=patch_size)\n",
    "    cell_patches_oa850 = extract_patches_at_positions(registered_frame_oa850, frame_cell_positions, mask=mask, patch_size=patch_size)\n",
    "    \n",
    "    if sigma > 0:\n",
    "        cell_patches_oa790 = cell_patches_oa790 / 255\n",
    "        cell_patches_oa850 = cell_patches_oa850 / 255\n",
    "\n",
    "        for i, (patch_790, patch_850) in enumerate(zip(cell_patches_oa790, cell_patches_oa850)):\n",
    "            cell_patches_oa790[i] = gaussian(patch_790, sigma=sigma)\n",
    "            cell_patches_oa850[i] = gaussian(patch_850, sigma=sigma)\n",
    "\n",
    "        cell_patches_oa790 = np.uint8(cell_patches_oa790 * 255)\n",
    "        cell_patches_oa850 = np.uint8(cell_patches_oa850 * 255)\n",
    "    \n",
    "    return cell_patches_oa790, cell_patches_oa850"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = video_sessions[1]\n",
    "vs.cell_positions[vs.validation_frame_idx]\n",
    "\n",
    "registered_frame_oa850_clone = vs.registered_frames_oa850.mean(0)\n",
    "registered_frame_oa850_clone = registered_frame_oa850_clone[..., np.newaxis]\n",
    "registered_frame_oa850_clone = np.concatenate((registered_frame_oa850_clone, registered_frame_oa850_clone, registered_frame_oa850_clone), axis=-1)\n",
    "\n",
    "window = 'Please Select a straight Segment with a lot of positions'\n",
    "roipoly_selector = CvRoipolySelector(window, registered_frame_oa850_clone)\n",
    "roipoly_selector.activate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageprosessing import enhance_motion_contrast_de_castro, SessionPreprocessor\n",
    "video_sessions = get_video_sessions(marked=True, validation=False)\n",
    "\n",
    "vsp = SessionPreprocessor(vs)\n",
    "vsp.preprocess_functions = [\n",
    "    lambda frames: enhance_motion_contrast_de_castro(frames, sigma=.75),\n",
    "    lambda frames: normalize_data(frames, (0,255)).astype(np.uint8),\n",
    "    lambda frames: enhance_motion_contrast_j_tam(frames, sigma=.3),\n",
    "    lambda frames: normalize_data(frames, (0, 255)).astype(np.uint8)\n",
    "#     \n",
    "]\n",
    "vsp.apply_preprocessing_to_oa790()\n",
    "vsp.apply_preprocessing_to_oa850()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(vs.frames_oa790[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_frames[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(normalize_data(processed_frames[0], (0, 255)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs.frames_oa790[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import gaussian\n",
    "\n",
    "dxs = {}\n",
    "dys = {}\n",
    "template_matchers = {}\n",
    "feature_matchers = {}\n",
    "for frame_idx in vs.cell_positions:\n",
    "    template_matcher = TemplateMatcher()\n",
    "\n",
    "    cell_patches_oa790, cell_patches_oa850 =\\\n",
    "    create_average_images(vs, \n",
    "                          frame_idx=frame_idx, \n",
    "                          mask=roipoly_selector.mask,\n",
    "                          patch_size=51,\n",
    "                          sigma=1)\n",
    "    \n",
    "    avg_cell_oa790 = np.mean(cell_patches_oa790, axis=0)\n",
    "    avg_cell_oa850 = np.mean(cell_patches_oa850, axis=0)\n",
    "\n",
    "    s=.0\n",
    "    avg_cell_oa790 = avg_cell_oa790\n",
    "    # avg_cell_oa850 = match_histograms(avg_cell_oa850, avg_cell_oa790)\n",
    "\n",
    "    avg_cell_oa790 = gaussian(avg_cell_oa790, sigma=s)\n",
    "    avg_cell_oa850 = gaussian(avg_cell_oa850, sigma=s)\n",
    "    \n",
    "    template_matcher.im1 = avg_cell_oa790\n",
    "    template_matcher.im2 = avg_cell_oa850 \n",
    "    template_matcher.match()\n",
    "    \n",
    "    feature_matcher = FeatureMatcher(avg_cell_oa790, avg_cell_oa850)\n",
    "    feature_matcher.match()\n",
    "    \n",
    "    dxs[frame_idx] = template_matcher.dx\n",
    "    dys[frame_idx] = template_matcher.dy\n",
    "    template_matchers[frame_idx] = template_matcher\n",
    "    feature_matchers[frame_idx] = feature_matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame_idx in template_matchers:\n",
    "    template_matchers[frame_idx].visualize_matching()\n",
    "#     feature_matchers[frame_idx].visualize_matching()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matchers[0].visualize_matching()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_matcher = TemplateMatcher()\n",
    "template_matcher.im1 = avg_cell_oa790\n",
    "template_matcher.im2 = avg_cell_oa850\n",
    "template_matcher.match()\n",
    "template_matcher.visualize_matching()#savename=os.path.join(report_images_folder, f'{os.path.splitext(vs.basename)[0]}_avg_cell'))\n",
    "template_matcher.dx, template_matcher.dy, np.sqrt(template_matcher.dx**2 + template_matcher.dy**2), template_matcher.cx, template_matcher.cy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matcher = FeatureMatcher(np.uint8(np.round(avg_cell_oa790)), np.uint8(np.round(avg_cell_oa850)))\n",
    "feature_matcher.match()\n",
    "\n",
    "plt.subplots_adjust(wspace=0.005, hspace=2)\n",
    "feature_matcher.visualize_matching()\n",
    "plt.subplots_adjust(wspace=0.005, hspace=2)\n",
    "\n",
    "feature_matcher.dx, feature_matcher.dy, np.sqrt(feature_matcher.dx**2 + feature_matcher.dy**2), feature_matcher.im2_x, feature_matcher.im2_y, os.path.join(report_images_folder, f'{os.path.splitext(vs.basename)[0]}_feature_matching.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
