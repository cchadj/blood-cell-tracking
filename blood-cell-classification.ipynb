{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter Notebook settings\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "%autosave 1\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Plotting settings\n",
    "import matplotlib.pyplot as plt\n",
    "size=15\n",
    "params = {'legend.fontsize': 'large',\n",
    "          'figure.figsize': (20,8),\n",
    "          'axes.labelsize': size,\n",
    "          'axes.titlesize': size,\n",
    "          'xtick.labelsize': size*0.75,\n",
    "          'ytick.labelsize': size*0.75,\n",
    "          'axes.titlepad': 5}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "from cnnlearning import *\n",
    "from learningutils import *\n",
    "from patchextraction import *\n",
    "from imageprosessing import *\n",
    "from nearest_neighbors import *\n",
    "from evaluation import *\n",
    "from classificationutils import *\n",
    "from sharedvariables import *\n",
    "from vesseldetection import *\n",
    "from generate_datasets import *\n",
    "from train_model import load_model_from_cache, train_model_demo\n",
    "from plotutils import plot_images_as_grid, plot_dataset_as_grid, no_ticks\n",
    "from sharedvariables import get_video_sessions\n",
    "\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "patch_size=21\n",
    "temporal_width=1\n",
    "do_hist_match=False\n",
    "n_negatives_per_positive=1\n",
    "standardize_dataset=True\n",
    "\n",
    "try_load_from_cache=False\n",
    "\n",
    "verbose=False\n",
    "very_verbose=False\n",
    "\n",
    "### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###\n",
    "trainset, validset,\\\n",
    "cell_images, non_cell_images,\\\n",
    "cell_images_marked, non_cell_images_marked, hist_match_template =\\\n",
    "get_cell_and_no_cell_patches(\n",
    "    patch_size=patch_size,\n",
    "    temporal_width=temporal_width,\n",
    "    n_negatives_per_positive=n_negatives_per_positive,\n",
    "    do_hist_match=do_hist_match,\n",
    "    try_load_from_cache=try_load_from_cache,\n",
    "    standardize_dataset=standardize_dataset,\n",
    "    v=verbose,\n",
    "    vv=very_verbose,\n",
    ")\n",
    "\n",
    "print(\"Cell images:\", cell_images.shape)\n",
    "print(\"Non cell images\", non_cell_images.shape)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Plotting...')\n",
    "fig, axes = plt.subplots(4, 6, figsize=(20, 10))\n",
    "no_ticks(axes)\n",
    "\n",
    "    \n",
    "for i, ax in enumerate(axes[0, :]):\n",
    "    ax.imshow(cell_images[i], cmap='gray')\n",
    "    ax.set_title('Cell Image')\n",
    "\n",
    "for i, ax in enumerate(axes[1, :]):\n",
    "    axes[1, i].imshow(cell_images_marked[i], cmap='gray')\n",
    "    ax.set_title('Cell Image marked')\n",
    "\n",
    "for i, ax in enumerate(axes[2, :]):\n",
    "    ax.imshow(non_cell_images[i], cmap='gray')\n",
    "    ax.set_title('Non Cell Image')\n",
    "    \n",
    "for i, ax in enumerate(axes[3, :]):\n",
    "    ax.imshow(non_cell_images_marked[i], cmap='gray')\n",
    "    ax.set_title('Non Cell image marked')\n",
    "\n",
    "if do_hist_match:\n",
    "    plt.figure()\n",
    "    plt.imshow(hist_match_template, cmap='gray')\n",
    "    plt.title('Histogram matching template')\n",
    "    \n",
    "    \n",
    "from torch.utils.data import DataLoader\n",
    "loader = DataLoader(trainset, batch_size=len(trainset),\n",
    "                     shuffle=False, num_workers=4)\n",
    "\n",
    "# for im, lbl in loader:\n",
    "#     print(f'Trainset minimum and maximum:', im.min(), im.max())\n",
    "    \n",
    "\n",
    "assert len(cell_images.shape) in [3, 4], 'Cell images should be NxHxWxC or NxHxW (grayscale)'\n",
    "assert cell_images.dtype == np.uint8 and non_cell_images.dtype == np.uint8, 'We want the patches to be uint'\n",
    "assert cell_images.min() >= 0 and cell_images.max() <= 255\n",
    "assert non_cell_images.min() >= 0 and non_cell_images.max() <= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnlearning import train, CNN, TrainingTracker\n",
    "\n",
    "train_params = collections.OrderedDict(\n",
    "    trainset=trainset,\n",
    "    validset=validset,\n",
    "    epochs=4000,\n",
    "    lr = .001,\n",
    "    weight_decay=5e-4,\n",
    "    batch_size=1024 * 7,\n",
    "    do_early_stop=True,  # Optional default True\n",
    "    early_stop_patience=80,\n",
    "    learning_rate_scheduler_patience=20,\n",
    "    shuffle=True)\n",
    "model = CNN(dataset_sample=trainset).to(device)\n",
    "\n",
    "results = train(model, train_params, criterion=torch.nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = collections.OrderedDict(\n",
    "    epochs=4000,\n",
    "    lr = .001,\n",
    "    weight_decay=5e-4,\n",
    "    batch_size=1024 * 12,\n",
    "    do_early_stop=True,  # Optional default True\n",
    "    early_stop_patience=80,\n",
    "    learning_rate_scheduler_patience=20,\n",
    "    shuffle=True)\n",
    "train_model_demo(patch_size=21,\n",
    "                 do_hist_match=False,\n",
    "                 n_negatives_per_positive=2,\n",
    "                 standardize_dataset=True,\n",
    "                 train_params=train_params,\n",
    "                 try_load_from_cache=False,\n",
    "                 additional_displays=['test'],\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm1a =hist_match_images(cell_images, cell_images[0])\n",
    "hm1b =hist_match_images(non_cell_images, cell_images[0])\n",
    "\n",
    "hm2a = hist_match_2(cell_images, cell_images[0])\n",
    "hm2b = hist_match_2(non_cell_images, cell_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "patch_size=21\n",
    "do_hist_match=False\n",
    "n_negatives_per_positive=1\n",
    "standa\n",
    "\n",
    "overwrite_cache=True\n",
    "verbose=False\n",
    "very_verbose=False\n",
    "\n",
    "#### #### #### #### #### #### ####\n",
    "cell_images, non_cell_images, cell_images_marked, non_cell_images_marked =\\\n",
    "    create_cell_and_no_cell_patches(patch_size=patch_size,\n",
    "                                    do_hist_match=False,\n",
    "                                    n_negatives_per_positive=1,\n",
    "                                    v=verbose, vv=very_verbose)\n",
    "\n",
    "print('Creating histogram matched images')\n",
    "template = cell_images[0]\n",
    "histogram_matched_cell_images = hist_match_images(cell_images, template)\n",
    "histogram_matched_non_cell_images = hist_match_images(non_cell_images, template)\n",
    "\n",
    "\n",
    "normalized_histogram_matched_cell_images = normalize_data(histogram_matched_cell_images, (0, 255),\n",
    "                                                          data_range=(template.min(), template.max()))\n",
    "normalized_histogram_matched_non_cell_images = normalize_data(histogram_matched_non_cell_images, (0, 255),\n",
    "                                                              data_range=(template.min(), template.max()))\n",
    "\n",
    "histogram_matched_cell_images_marked = hist_match_images(cell_images_marked, template)\n",
    "histogram_matched_non_cell_images_marked = hist_match_images(non_cell_images_marked, template)\n",
    "\n",
    "\n",
    "print(cell_images.shape, non_cell_images.shape, cell_images.dtype, non_cell_images_marked.dtype, cell_images_marked.dtype, non_cell_images_marked.dtype)\n",
    "print(cell_images.min(), cell_images.max(), non_cell_images.min(), non_cell_images.max())\n",
    "trainset, validset = create_dataset_from_cell_and_no_cell_images(cell_images, non_cell_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images_as_grid(equalize_adapthist_imagestack(np.uint8(hm1a)))\n",
    "plot_images_as_grid(equalize_adapthist_imagestack(np.uint8(hm1b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images_as_grid(equalize_adapthist_imagestack(np.uint8(hm2a)))\n",
    "plot_images_as_grid(equalize_adapthist_imagestack(np.uint8(hm2b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.round(hist_match_2(vs.frames_oa790, cell_images[0])).astype(np.uint8)[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images_as_grid(equalize_adapthist_imagestack(np.uint8(hm2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images_as_grid(hm2.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images_as_grid(hm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageprosessing import hist_match_2, hist_match_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagestack_to_vstacked_image(framestack):\n",
    "    return np.hstack(np.split(framestack, len(framestack), axis=0)).squeeze()\n",
    "def vstacked_image_to_imagestack(stacked_image, n_images):\n",
    "    return np.array(np.split(stacked_image, n_images, axis=0)) \n",
    "\n",
    "def imagestack_to_hstacked_image(framestack):\n",
    "    return np.hstack([f.squeeze() for f in np.split(framestack, len(framestack))])\n",
    "def hstacked_image_to_imagestack(stacked_image, n_images):\n",
    "    return np.array(np.split(stacked_image, n_images, axis=1))  \n",
    "\n",
    "assert np.array_equal(vstacked_image_to_imagestack(imagestack_to_vstacked_image(vs.frames_oa790), len(vs.frames_oa790)), vs.frames_oa790)\n",
    "assert np.array_equal(hstacked_image_to_imagestack(imagestack_to_hstacked_image(vs.frames_oa790), len(vs.frames_oa790)), vs.frames_oa790)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize_adapthist_imagestack(imstack):\n",
    "    return  vstacked_image_to_imagestack(equalize_adapthist(imagestack_to_vstacked_image(imstack)), len(imstack))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equalised_frames = equalize_adapthist_imagestack(vs.frames_oa790)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(equalised_frames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(plt.imshow(imagestack_to_hstacked_image(video_sessions[15].frames_oa790[:10]), cmap='gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = cv2.calcHist([f for f in vs.frames_oa790],[0],None,[256],[0, 256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.calcHist([f for f in vs.frames_oa790], channels=1, mask=np.ones_like(vs.frames_oa790[0]), histSize=256, ranges=[0, 256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(vs.frames_oa790[0], cmap='gray')\n",
    "equalize_adapthist(vs.frames_oa790[0]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(equalize_adapthist(vs.frames_oa790[0]), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import equalize_adapthist, equalize_hist\n",
    "equalize_adapthist(histogram_matched_cell_images)\n",
    "plot_images_as_grid(histogram_matched_cell_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, validset = create_dataset_from_cell_and_no_cell_images(cell_images, non_cell_images)\n",
    "loader = DataLoader(trainset, batch_size=100000)\n",
    "\n",
    "for ims, lbls in loader:\n",
    "    print(ims.min(), ims.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, validset = create_dataset_from_cell_and_no_cell_images(histogram_matched_cell_images, histogram_matched_non_cell_images)\n",
    "loader = DataLoader(trainset, batch_size=100000)\n",
    "\n",
    "for ims, lbls in loader:\n",
    "    print(ims.min(), ims.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, validset = create_dataset_from_cell_and_no_cell_images(normalized_histogram_matched_cell_images,\n",
    "                                                                 normalized_histogram_matched_non_cell_images)\n",
    "loader = DataLoader(trainset, batch_size=100000)\n",
    "\n",
    "for ims, lbls in loader:\n",
    "    print(ims.min(), ims.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Normalised images min max', (normalized_histogram_matched_cell_images.min(), \n",
    "normalized_histogram_matched_cell_images.max()), \\\n",
    "(normalized_histogram_matched_non_cell_images.min(), \n",
    "normalized_histogram_matched_non_cell_images.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images_as_grid(cell_images)\n",
    "plot_images_as_grid(histogram_matched_cell_images)\n",
    "plot_images_as_grid(histogram_matched_cell_images_marked)\n",
    "plot_images_as_grid(non_cell_images)\n",
    "plot_images_as_grid(histogram_matched_non_cell_images)\n",
    "plot_images_as_grid(histogram_matched_non_cell_images_marked)\n",
    "plot_images_as_grid(normalized_histogram_matched_cell_images)\n",
    "plot_images_as_grid(normalized_histogram_matched_non_cell_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, validset = create_dataset_from_cell_and_no_cell_images(hm1a, hm1b)\n",
    "model = CNN().to(device)\n",
    "\n",
    "train_params = collections.OrderedDict(\n",
    "    # lr = .001,\n",
    "    # optimizer=torch.optim.SGD(model.parameters(), lr=.001, weight_decay=5e-5, momentum=0.9),\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=.001, weight_decay=5e-4),\n",
    "    batch_size=1024 * 7,\n",
    "    do_early_stop=True,  # Optional default True\n",
    "    early_stop_patience=80,\n",
    "    learning_rate_scheduler_patience=100,\n",
    "    epochs=4000,\n",
    "    shuffle=True,\n",
    "    # valid_untrunsformed_normals = valid_untrunsformed_normals,\n",
    "    trainset=trainset,\n",
    "    validset=validset,\n",
    ")\n",
    "\n",
    "results = train(model,\n",
    "                train_params,\n",
    "                criterion=torch.nn.CrossEntropyLoss(),\n",
    "                device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, validset = create_dataset_from_cell_and_no_cell_images(normalized_histogram_matched_cell_images, \n",
    "                                                                 normalized_histogram_matched_non_cell_images)\n",
    "model = CNN(\n",
    "    convolutional=\n",
    "    nn.Sequential(\n",
    "        nn.Conv2d(1, 32, padding=2, kernel_size=5),\n",
    "        # PrintLayer(\"1\"),\n",
    "        nn.BatchNorm2d(32),\n",
    "        # PrintLayer(\"2\"),\n",
    "        nn.MaxPool2d(kernel_size=(3, 3), stride=2),\n",
    "        # PrintLayer(\"3\"),\n",
    "\n",
    "        nn.Conv2d(32, 32, padding=2, kernel_size=5),\n",
    "        # PrintLayer(\"4\"),\n",
    "        nn.BatchNorm2d(32),\n",
    "        # PrintLayer(\"5\"),\n",
    "        nn.ReLU(),\n",
    "        # PrintLayer(\"6\"),\n",
    "        nn.AvgPool2d(kernel_size=3, padding=1, stride=2),\n",
    "        # PrintLayer(\"7\"),\n",
    "\n",
    "        nn.Conv2d(32, 64, padding=2, kernel_size=5),\n",
    "        # PrintLayer(\"9\"),\n",
    "        nn.BatchNorm2d(64),\n",
    "        # PrintLayer(\"11\"),\n",
    "        nn.ReLU(),\n",
    "        nn.AvgPool2d(kernel_size=3, padding=1, stride=2),\n",
    "        # PrintLayer(\"12\"),\n",
    "    ),\n",
    "    dense=\n",
    "    nn.Sequential(\n",
    "        nn.Linear(576, 64),\n",
    "        nn.BatchNorm1d(64),\n",
    "        nn.ReLU(64),\n",
    "        nn.Linear(64, 32),\n",
    "        nn.BatchNorm1d(32),\n",
    "        nn.Linear(32, 2),\n",
    "        #   nn.Softmax()\n",
    "    )).to(device)\n",
    "\n",
    "train_params = collections.OrderedDict(\n",
    "    # lr = .001,\n",
    "    # optimizer=torch.optim.SGD(model.parameters(), lr=.001, weight_decay=5e-5, momentum=0.9),\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=.001, weight_decay=5e-4),\n",
    "    batch_size=1024 * 7,\n",
    "    do_early_stop=True,  # Optional default True\n",
    "    early_stop_patience=80,\n",
    "    learning_rate_scheduler_patience=100,\n",
    "    epochs=4000,\n",
    "    shuffle=True,\n",
    "    # valid_untrunsformed_normals = valid_untrunsformed_normals,\n",
    "    trainset=trainset,\n",
    "    validset=validset,\n",
    ")\n",
    "\n",
    "results = train(model,\n",
    "                train_params,\n",
    "                criterion=torch.nn.CrossEntropyLoss(),\n",
    "                device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert cell_images.dtype == np.float32 and cell_images.max() <= 1. and cell_images.min() >= .0\n",
    "assert non_cell_images.dtype == np.float32 and non_cell_images.max() <= 1. and non_cell_images.min() >= .0\n",
    "cell_images.min(), cell_images.max(), non_cell_images.min(), non_cell_images.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_images_as_grid(cell_images[:10])\n",
    "plot_images_as_grid(non_cell_images[:10])\n",
    "plot_images_as_grid(cell_images_marked[:10])\n",
    "plot_images_as_grid(non_cell_images_marked[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Create classifier model\n",
    "Either load model from cache or train a new one.\n",
    "\n",
    "**You can interrupt**, or Ctr - C at any time to stop training and get the best model at the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "load_model_from_cache = False\n",
    "\n",
    "train_params = collections.OrderedDict(\n",
    "    epochs=4000,\n",
    "    lr = .001,\n",
    "    weight_decay=5e-5,\n",
    "    batch_size=1024 * 12,\n",
    "    do_early_stop=True,  # Optional default True\n",
    "    early_stop_patience=80,\n",
    "    learning_rate_scheduler_patience=100,\n",
    "    shuffle=True)\n",
    "\n",
    "### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###\n",
    "model = train_model_demo(patch_size=patch_size,\n",
    "                         do_hist_match=do_hist_match, \n",
    "                         n_negatives_per_positive=n_negatives_per_positive,\n",
    "                         load_from_cache=load_model_from_cache,\n",
    "                         train_params=train_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation\n",
    "## Evaluation on a sample frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load sample frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 3\n",
    "video_file = unmarked_labeled_video_OA790_filenames[idx]\n",
    "csv_file = csv_cell_cords_OA790_filenames[idx]\n",
    "std_image = std_confocal_images_for_labeled_OA790[idx]\n",
    "\n",
    "assert files_of_same_source(video_file, csv_file)\n",
    "video_file, csv_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = get_frames_from_video(video_file)[..., 0]\n",
    "\n",
    "#### #### #### #### #### #### #### #### #### #### #### #### #### #### #### #### ####\n",
    "ground_truth_positions = get_positions_from_csv(csv_file, 1)\n",
    "sample_frame = frames[0, ...].astype(np.float32) / 255\n",
    "\n",
    "if do_hist_match:\n",
    "    sample_frame = np.float32(hist_match(sample_frame, template))\n",
    "\n",
    "print('Frames shape', frames.shape)\n",
    "print('Sample frame', sample_frame.shape)\n",
    "print('Blood cell positions for all frames', all_video_cell_coords.shape)\n",
    "print()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "axes[0].imshow(sample_frame, cmap='gray')\n",
    "axes[0].scatter(ground_truth_positions[:, 0], ground_truth_positions[:, 1], label='Manual positions')\n",
    "axes[0].set_title('Sample frame')\n",
    "axes[0].legend()\n",
    "\n",
    "vessel_image = plt.imread(std_image)\n",
    "axes[1].imshow(vessel_image, cmap='gray')\n",
    "axes[1].scatter(ground_truth_positions[:, 0], ground_truth_positions[:, 1], label='Manual positions')\n",
    "axes[1].set_title('Vessel standard deviation image')\n",
    "axes[1].legend()\n",
    "\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig_size = fig.get_size_inches()\n",
    "fig.set_size_inches((fig_size[0] * 3, fig_size[1] * 3))\n",
    "\n",
    "sample_frame_cell_patches = extract_patches_at_positions(sample_frame, ground_truth_positions, patch_size=patch_size)\n",
    "\n",
    "rxs, rys = get_random_point_on_rectangle(ground_truth_positions[:, 0], \n",
    "                                         ground_truth_positions[:, 1], \n",
    "                                         patch_size)\n",
    "\n",
    "non_cell_positions = np.array([rxs, rys]).T\n",
    "remove_positions_too_close_to_border_indices = get_positions_too_close_to_border(non_cell_positions,\n",
    "                                                                                 image_shape=sample_frame.shape[:2], \n",
    "                                                                                 patch_size=patch_size)\n",
    "non_cell_positions_new = np.delete(non_cell_positions, \n",
    "                                   remove_positions_too_close_to_border_indices,\n",
    "                                   axis=0)\n",
    "\n",
    "sample_frame_non_cell_patches = extract_patches_at_positions(sample_frame, \n",
    "                                                             non_cell_positions_new,\n",
    "                                                             patch_size=patch_size)\n",
    "\n",
    "print(sample_frame_cell_patches.shape)\n",
    "print('Positive accuracy on cells from sample frame:\\t\\t',\n",
    "     f'{classify_images(sample_frame_cell_patches, model).sum().item() / len(sample_frame_cell_patches):.3f}')\n",
    "print('Negative accuracy on non cells from sample frame:\\t',\n",
    "     f'{(1 - classify_images(sample_frame_non_cell_patches, model)).sum().item() / len(sample_frame_non_cell_patches):.3f}')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vessel mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vesseldetection import create_vessel_mask\n",
    "\n",
    "vessel_image_bordered = cv2.copyMakeBorder(vessel_image, *patch_size, *patch_size, cv2.BORDER_REFLECT)\n",
    "        \n",
    "vessel_mask = create_vessel_mask(vessel_image_bordered,\n",
    "                                 opening_kernel_size=3,\n",
    "                                 n_iterations=4,\n",
    "                                 visualise_intermediate_steps=True)\n",
    "vessel_mask = vessel_mask[patch_size[0]:(vessel_mask.shape[0] - patch_size[0]) ,\n",
    "                          patch_size[1]:(vessel_mask.shape[1] - patch_size[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(vessel_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate probability map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def create_probability_map(image,\n",
    "                           model,\n",
    "                           patch_size=(21, 21),\n",
    "                           padding=cv2.BORDER_REPLICATE,\n",
    "                           device='cuda',\n",
    "                           mask=None,\n",
    "                           ):\n",
    "    if len(image.shape) == 2:\n",
    "        # Add channel at end if grayscale. HxW -> HxWx1\n",
    "        image = image[:, :, np.newaxis]\n",
    "\n",
    "    # print('Image shape', image.shape)\n",
    "    # if mask is not None then create patches for every pixel.\n",
    "    if mask is None:\n",
    "        mask = np.ones(image.shape[:2], dtype=np.bool)\n",
    "\n",
    "\n",
    "    model = model.eval()\n",
    "    model = model.to(device)\n",
    "\n",
    "    # print('Mask shape', mask.shape)\n",
    "    # flatten mask to get indices to index patches\n",
    "    mask_flattened = mask.reshape(-1)\n",
    "    vessel_pixel_indices = np.where(mask_flattened)[0]\n",
    "\n",
    "    patches = extract_patches(image, patch_size, padding=padding)[vessel_pixel_indices]\n",
    "    label_probabilities = label_probability(patches, model, device)\n",
    "\n",
    "    probability_map = np.zeros(image.shape[:2], dtype=np.float32)\n",
    "    rows, cols = np.unravel_index(vessel_pixel_indices, probability_map.shape[:2])\n",
    "    probability_map[rows, cols] = label_probabilities[:, 1]\n",
    "\n",
    "    return probability_map\n",
    "\n",
    "\n",
    "probability_map = create_probability_map(sample_frame,\n",
    "                                         model,\n",
    "                                         mask=None,\n",
    "                                         patch_size=patch_size,\n",
    "                                         device=device)\n",
    "plt.imshow(probability_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate positions from probability map\n",
    "\n",
    "* First calculate the best $σ$ for the gaussian blur and the best $H$ for the extended maxima, maximising Dice's coefficient\n",
    "* Using the best $σ$ and $Η$ find the positions by binarising the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = np.uint8(probability_map * 255)\n",
    "plt.imshow(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_blurred = mh.gaussian_filter(pm, 3)\n",
    "\n",
    "plt.imshow(pm_blurred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_sigmas = np.arange(0.125, 3.25, 0.25)\n",
    "for s in gauss_sigmas:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_map = pm\n",
    "pathlib.Path(CACHED_DICE).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "filename = os.path.join(CACHED_DICE, \n",
    "                        f'blood_cell_dices_coefficient_sigma_h_{patch_size[0]}_hm_{str(do_hist_match).lower()}.csv')\n",
    "try:\n",
    "    print(f'Loading dices coefficient and correspoding sigmas and hs from:\\n {filename}')\n",
    "    df = pd.read_csv(filename, usecols=(1, 2, 3))\n",
    "    print('Done')\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found. Finding sigma and h that maximise Dice's coefficient...\")\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    dices_coefficients = []\n",
    "    sigmas = []\n",
    "    Hs = []\n",
    "\n",
    "    gauss_sigmas = np.arange(0.125, 3.25, 0.25).astype(np.float32)\n",
    "    extended_maxima_Hs = np.arange(0, 255, 1).astype(np.uint8)\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    max_dices_coeff = 0\n",
    "    best_sigma = gauss_sigmas[0]\n",
    "    best_H = extended_maxima_Hs[0]\n",
    "    c = 0\n",
    "    for s in tqdm(gauss_sigmas):\n",
    "        for h in extended_maxima_Hs:\n",
    "            estimated_positions = get_cell_positions_from_probability_map(probability_map, s, h)\n",
    "\n",
    "            dices_coeff, _, _ = evaluate_results(ground_truth_positions, \n",
    "                                                 estimated_positions,\n",
    "                                                 sample_frame,\n",
    "                                                 patch_size=(19, 19))\n",
    "            if dices_coeff < 0:\n",
    "                continue\n",
    "            if dices_coeff > max_dices_coeff:\n",
    "                max_dices_coeff = dices_coeff\n",
    "                best_sigma = s\n",
    "                best_H = h\n",
    "\n",
    "            dices_coefficients.append(dices_coeff)\n",
    "            sigmas.append(s)\n",
    "            Hs.append(h)\n",
    "            \n",
    "\n",
    "            df = pd.DataFrame()\n",
    "            df['dices_coefficient'] = dices_coefficients\n",
    "            df['sigma'] = sigmas\n",
    "            df['extended_maxima_h'] = Hs\n",
    "            if c % 50 == 0;\n",
    "                print('progress is being made')\n",
    "#             if c % 30 == 0:\n",
    "#                 clear_output()\n",
    "#                 display(df)\n",
    "            c += 1\n",
    "            \n",
    "    print(f'Saving results to {filename}')\n",
    "    df.to_csv(filename)\n",
    "    print('Done')\n",
    "    \n",
    "pd.set_option('display.max_rows', 3)\n",
    "display(df)\n",
    "\n",
    "max_dices_coeff_idx = df['dices_coefficient'].argmax()\n",
    "\n",
    "print(\"Maximum Dice's coefficient values:\\n\")\n",
    "print(df.iloc[max_dices_coeff_idx])\n",
    "best_dices_coefficient = df.loc[max_dices_coeff_idx, 'dices_coefficient']\n",
    "best_sigma = df.loc[max_dices_coeff_idx, 'sigma']\n",
    "best_h = df.loc[max_dices_coeff_idx, 'extended_maxima_h']\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(probability_map)\n",
    "plt.scatter(ground_truth_positions[:, 0], ground_truth_positions[:, 1], c='red', s=8)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig_size = fig.get_size_inches()\n",
    "fig.set_size_inches((fig_size[0] * 2,\n",
    "                     fig_size[1] * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 0.4\n",
    "seed = image - h\n",
    "dilated = reconstruction(seed, mask, method='dilation')\n",
    "hdome = image - dilated\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(nrows=1, ncols=3, figsize=(8, 2.5))\n",
    "yslice = 197\n",
    "\n",
    "ax0.plot(mask[yslice], '0.5', label='mask')\n",
    "ax0.plot(seed[yslice], 'k', label='seed')\n",
    "ax0.plot(dilated[yslice], 'r', label='dilated')\n",
    "ax0.set_ylim(-0.2, 2)\n",
    "ax0.set_title('image slice')\n",
    "ax0.set_xticks([])\n",
    "ax0.legend()\n",
    "\n",
    "ax1.imshow(dilated, vmin=image.min(), vmax=image.max(), cmap='gray')\n",
    "ax1.axhline(yslice, color='r', alpha=0.4)\n",
    "ax1.set_title('dilated')\n",
    "ax1.axis('off')\n",
    "\n",
    "ax2.imshow(hdome, cmap='gray')\n",
    "ax2.axhline(yslice, color='r', alpha=0.4)\n",
    "ax2.set_title('image - dilated')\n",
    "ax2.axis('off')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imhmax_res = imhmaxima(prob_map_uint, 125)\n",
    "Image.fromarray(imhmax_res).save('imhmaxima_result.png')\n",
    "plt.imshow(imhmax_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_maxima_result = mh.regmax(imhmax_res, Bc=np.ones((3, 3), dtype=np.bool8))\n",
    "plt.imshow(extended_maxima_result)\n",
    "Image.fromarray(extended_maxima_result.astype(np.uint8)).save('extended_maxima_result.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imextendedmax(prob_map_uint, 125))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imextendedmax(prob_map_uint, 125))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(prob_map_uint).save('prob_map_uint.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(extrema.h_maxima(pm_sm, 125, structel)).save('tmp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?extrema.h_maxima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(pm_sm).save('pm_sm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structel = np.ones([3, 3], dtype=np.bool8)\n",
    "plt.imshow(extrema.h_maxima(prob_map_uint, 125, structel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imextendedmax(probability_map, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_extended_max_bw = imextendedmax(probability_map, extended_maxima_H)\n",
    "\n",
    "labeled, nr_objects = mh.label(pm_extended_max_bw)\n",
    "\n",
    "# print(np.where(pm_extended_max_bw)[0])\n",
    "pm_extended_max = probability_map.copy()\n",
    "pm_extended_max[pm_extended_max_bw] = 0\n",
    "\n",
    "labeled, nr_objects = mh.label(pm_extended_max)\n",
    "predicted_cell_positions = mh.center_of_mass(probability_map, labeled)[:, [1, 0]]\n",
    "\n",
    "\n",
    "plt.imshow(pm_extended_max_bw)\n",
    "plt.scatter(predicted_cell_positions[:, 0], predicted_cell_positions[:, 1], c='red', s=8)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig_size = fig.get_size_inches()\n",
    "fig.set_size_inches((fig_size[0] * 2,\n",
    "                     fig_size[1] * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(probability_map)\n",
    "plt.scatter(estimated_positions[:, 0], estimated_positions[:, 1], c='red', s=8)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig_size = fig.get_size_inches()\n",
    "fig.set_size_inches((fig_size[0] * 2,\n",
    "                     fig_size[1] * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(np.where(pm_extended_max_bw)[0])\n",
    "pm_extended_max = probability_map.copy()\n",
    "pm_extended_max[pm_extended_max_bw] = 0\n",
    "\n",
    "# print(pm_extended_max)\n",
    "# Notice, the positions from the csv is x,y. The result from the probability is y,x so we swap.\n",
    "predicted_cell_positions = mh.center_of_mass(pm_extended_max_bw, labeled)[:, [1, 0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_sigma = best_sigma\n",
    "extended_maxima_H = best_h\n",
    "\n",
    "estimated_positions = get_cell_positions_from_probability_map(probability_map, \n",
    "                                                              gauss_sigma,\n",
    "                                                              extended_maxima_H,\n",
    "                                                              visualise_intermediate_results=True)\n",
    "\n",
    "dices_coeff, _, _ = evaluate_results(ground_truth_positions, \n",
    "                                     estimated_positions,\n",
    "                                     sample_frame,\n",
    "                                     patch_size=patch_size)\n",
    "plt.figure()\n",
    "# print(estimated_positions)\n",
    "plt.title(f\"Dice's coefficient {dices_coeff:.3f}\")\n",
    "plt.imshow(sample_frame, cmap='gray')\n",
    "plt.scatter(ground_truth_positions[:, 0], ground_truth_positions[:, 1],  s=51, label='Ground truth positions')\n",
    "plt.scatter(estimated_positions[:, 0], estimated_positions[:, 1], s=51, label='Estimated positions')\n",
    "plt.legend()\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig_size = fig.get_size_inches()\n",
    "fig.set_size_inches((fig_size[0] * 2,\n",
    "                     fig_size[1] * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Veselness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(registered_videos_2_stdev_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(registered_videos_2_stdev_images[11])\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_videos_2_stdev_images[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = plt.imread(registered_videos_2_stdev_images[11])\n",
    "f = np.fft.fft2(img)\n",
    "fshift = np.fft.fftshift(f)\n",
    "magnitude_spectrum = 20*np.log(np.abs(fshift))\n",
    "\n",
    "fshift_filtered = fshift.copy()\n",
    "fshift_filtered[250:275, ...] = 0.001\n",
    "magnitude_spectrum_filtered = 20*np.log(np.abs(fshift_filtered))\n",
    "# shift back (we shifted the center before)\n",
    "f_ishift = np.fft.ifftshift(fshift_filtered)\n",
    "# inverse fft to get the image back \n",
    "img_back = np.abs(np.fft.ifft2(f_ishift))\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(50, 50))\n",
    "axes[0].imshow(img, cmap = 'gray')\n",
    "axes[0].set_title('Input Image'), plt.xticks([]), plt.yticks([])\n",
    "axes[1].imshow(magnitude_spectrum, cmap = 'gray')\n",
    "axes[1].set_title('Magnitude Spectrum'), plt.xticks([]), plt.yticks([])\n",
    "axes[2].imshow(magnitude_spectrum_filtered, cmap='gray')\n",
    "axes[2].set_title('Magnitude Spectrum filtered'), plt.xticks([]), plt.yticks([])\n",
    "axes[3].imshow(img_back, cmap='gray')\n",
    "axes[3].set_title('Recovered Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageEnhance\n",
    "from skimage import exposure\n",
    "plt.imshow(exposure.equalize_hist(img_back), cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_videos_2_stdev_images[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 6\n",
    "video_filename = registered_videos_2_filenames[idx]\n",
    "mask_filename = registered_videos_2_mask_filenames[idx]\n",
    "\n",
    "frames = get_frames_from_video(video_filename, normalise=False)[..., 0]\n",
    "masks  = np.bool8(get_frames_from_video(mask_filename, normalise=False))[..., 0]\n",
    "\n",
    "avg_img, std_img = create_average_and_stdev_image(frames, masks)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(45, 45))\n",
    "axes[0].imshow(avg_img, cmap='gray')\n",
    "axes[1].imshow(std_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_img.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6, 4, figsize=(45, 45))\n",
    "vessel_images_all = []\n",
    "\n",
    "n_skip = 0\n",
    "skip_count = 0\n",
    "i = 0\n",
    "for row in range(axes.shape[0]):\n",
    "    for  col in range(axes.shape[1]):\n",
    "        if skip_count < n_skip:\n",
    "            skip_count += 1\n",
    "            i += 1\n",
    "            continue\n",
    "            \n",
    "        im = plt.imread(registered_videos_2_stdev_images[i])\n",
    "        # print(im.shape)\n",
    "        axes[row, col].imshow(im, cmap='gray')\n",
    "        axes[row, col].set_title(f'{im.shape} {i}')\n",
    "        vessel_images_all.append(im)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_images_to_keep_indices = [0, 3, 6, 9, 12, 15, 21]\n",
    "vessel_images = [vessel_images_all[idx] for idx in vessel_images_to_keep_indices]\n",
    "print(len(vessel_images))\n",
    "\n",
    "fig, axes = plt.subplots(1, len(vessel_images), figsize=(45, 45))\n",
    "\n",
    "max_intensity = 0\n",
    "for ax, im in zip(axes, vessel_images):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    if max_intensity < im.max():\n",
    "        max_intensity = im.max()\n",
    "max_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_images_normalised = [\n",
    "    cv2.normalize(im, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX) for im in vessel_images\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.filters\n",
    "\n",
    "n_remove_border = 100\n",
    "sample_vessel_image = vessel_images_normalised[6].copy()\n",
    "sample_vessel_image = np.uint8(sample_vessel_image)\n",
    "sample_vessel_image = sample_vessel_image[n_remove_border: sample_vessel_image.shape[0] - n_remove_border,\n",
    "                                          n_remove_border: sample_vessel_image.shape[1] - n_remove_border]\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 6, figsize=(60, 60))\n",
    "axes[0].imshow(sample_vessel_image, cmap='gray')\n",
    "\n",
    "\n",
    "# sample_vessel_image_blurred = skimage.filters.median(sample_vessel_image,  mode='nearest', cval=0)\n",
    "sample_vessel_image_blurred = sample_vessel_image\n",
    "# sample_vessel_image_blurred = skimage.filters.gaussian(sample_vessel_image_blurred, sigma=3)\n",
    "frangi_image = skimage.filters.frangi(sample_vessel_image_blurred, alpha=.5, beta=.5, black_ridges=False)\n",
    "frangi_image_normalised = cv2.normalize(frangi_image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
    "\n",
    "minLineLength = 1\n",
    "maxLineGap = 150\n",
    "\n",
    "binary_threshold = skimage.filters.threshold_otsu(frangi_image_normalised, nbins=256)\n",
    "BW = np.zeros_like(frangi_image_normalised)\n",
    "BW[frangi_image_normalised > binary_threshold * 0.5] = 1\n",
    "BW = np.uint8(BW)\n",
    "\n",
    "# lines = cv2.HoughLinesP(BW, 1, np.pi/180, 25, minLineLength=10, maxLineGap=300)\n",
    "# for line in lines:\n",
    "#     x1, y1, x2, y2 = line[0]\n",
    "#     cv2.line(BW, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
    "# BW = skimage.morphology.binary_dilation(BW)\n",
    "\n",
    "kernel = np.ones((13, 13),np.uint8)\n",
    "# closing = cv2.morphologyEx(BW, cv2.MORPH_CLOSE, kernel)\n",
    "dilation = cv2.dilate(BW, kernel, iterations=1)\n",
    "kernel = np.ones((7, 7),np.uint8)\n",
    "errosion = cv2.erode(dilation, kernel, iterations=2)\n",
    "\n",
    "axes[1].imshow(sample_vessel_image_blurred, cmap='gray')\n",
    "axes[2].imshow(frangi_image)\n",
    "axes[3].imshow(BW)\n",
    "axes[4].imshow(dilation)\n",
    "axes[5].imshow(errosion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skimage.filters.try_all_threshold(frangi_image, figsize=(18, 15), verbose=True)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?cv2.HoughLinesP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_remove_border = 100\n",
    "frangi_image = frangi_image[n_remove_border:frangi_image.shape[0] - n_remove_border, \n",
    "                            n_remove_border:frangi_image.shape[1] - n_remove_border]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frangi_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frangi_image.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_stdev_image_orig = plt.imread(registered_videos_stdev_images[0])\n",
    "sample_stdev_image = np.float32(sample_stdev_image_orig) / sample_stdev_image_orig.max()\n",
    "sample_stdev_image = np.uint8(sample_stdev_image * 255)\n",
    "print(sample_stdev_image.shape) \n",
    "plt.imshow(sample_stdev_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_stdev_image_orig[98, 98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_stdev_image_recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_stdev_image_recovered = np.float32(sample_stdev_image) / 255\n",
    "plt.imshow(sample_stdev_image_recovered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test offset of x and y  in registered videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_video_filename = registered_videos_filenames[0]\n",
    "registered_video_csv = registered_videos_registration_csv[0]\n",
    "print(registered_video_filename, registered_video_csv, sep='\\n')\n",
    "frames = get_frames_from_video(registered_videos_filenames[0])\n",
    "csv_df = pd.read_csv(registered_video_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "\n",
    "import matplotlib.animation\n",
    "\n",
    "xshifts = csv_df[' XShift']\n",
    "yshifts = csv_df[' YShift']\n",
    "\n",
    "def update(i):\n",
    "    print(i)\n",
    "    xshift = xshifts[i]\n",
    "    yshift = yshifts[i]\n",
    "\n",
    "    x = frames[i, ...]\n",
    "    ax.imshow(x, extent=[-x.shape[1]/2., x.shape[1]/2., -x.shape[0]/2., x.shape[0]/2. ])\n",
    "    ax.scatter(-xshift, yshift)\n",
    "\n",
    "    \n",
    "fig, ax = plt.subplots(1, 1, figsize=(25, 25))\n",
    "\n",
    "ani = matplotlib.animation.FuncAnimation(fig, \n",
    "                                         update,\n",
    "                                         frames=len(frames),\n",
    "                                         interval=1000, repeat=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.animation\n",
    "\n",
    "xshifts = csv_df[' XShift']\n",
    "yshifts = csv_df[' YShift']\n",
    "\n",
    "plt.sub\n",
    "plt.show()\n",
    "def update(i):\n",
    "    print(i)\n",
    "    xshift = xshifts[i]\n",
    "    yshift = yshifts[i]\n",
    "\n",
    "    x = frames[i, ...]\n",
    "    plt.imshow(x, extent=[-x.shape[1]/2., x.shape[1]/2., -x.shape[0]/2., x.shape[0]/2. ])\n",
    "    plt.scatter(xshift, yshift)\n",
    "\n",
    "        \n",
    "update(29)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0, len(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESC = 27\n",
    "def draw_circle(event,x,y,flags,param):\n",
    "    # x grows from left to right\n",
    "    # y grows from top to bottom\n",
    "    global mouseX,mouseY\n",
    "    if event == cv2.EVENT_LBUTTONDBLCLK:\n",
    "        cv2.circle(im,(x,y),100,(255,0,0),-1)\n",
    "        mouseX, mouseY = x,y\n",
    "        print(x, y)\n",
    "\n",
    "\n",
    "im = plt.imread(registered_videos_stdev_images[0])\n",
    "\n",
    "cv2.namedWindow('image')\n",
    "cv2.imshow('image', im)\n",
    "cv2.setMouseCallback('image',draw_circle)\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow('image', im)\n",
    "\n",
    "    #cv2.imshow('image',img)\n",
    "    k = cv2.waitKey(20) & 0xFF\n",
    "    if k == ESC or k == ord('q'):\n",
    "        break\n",
    "    elif k == ord('p'):\n",
    "        print(mouseX,mouseY)\n",
    "    else:\n",
    "        clear_output()\n",
    "        #print(k)\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image', im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread(registered_videos_stdev_images[0])\n",
    "  \n",
    "\n",
    "cv2.imshow('ok', im)    \n",
    "cv2.waitKey()  \n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ginput(3)\n",
    "plt.imshow(im)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  How to evaluate segmentation results\n",
    "\n",
    "1- Dice score: which is 2 times the intersection between your segmentation results with the ground truth (manual segmentation) divided by the sumof both of them\n",
    "D= 2 (A intersect B) / (A + B) \n",
    "2- Jaccard similarity: which is the ratio between the intersection and union of the segmented results and the ground truth\n",
    "J= (A intersect B) / (A union B) \n",
    "Hint: there is one relation between J and D that you can easily derive."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
