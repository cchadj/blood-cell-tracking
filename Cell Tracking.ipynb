{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from cnnlearning import *\n",
    "from learning_utils import *\n",
    "from cell_no_cell import *\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "SHARED_CONES = os.path.join(\".\", \"data\", \"ConesShare\")\n",
    "SHARED_VIDEOS_PATH = os.path.join(\".\", \"data\", \"Shared_Videos\")\n",
    "OUTPUT_FOLDER = os.path.join(\".\", \"data\", \"output\")\n",
    "TRAINED_MODEL_FOLDER = os.path.join(OUTPUT_FOLDER, \"trained_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dataset_as_grid(dataset, title=None):\n",
    "    \"\"\"\n",
    "    Plots a stack of images in a grid.\n",
    "\n",
    "    Arguments:\n",
    "        images: The images as NxHxWxC\n",
    "        title: Plot title\n",
    "    \"\"\"\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=60000,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    for batch in loader:\n",
    "        images = batch[0]\n",
    "        labels = batch[1]\n",
    "        \n",
    "        print(\"Images:\", images.shape)\n",
    "        print(\"Labels:\", labels.shape)\n",
    "        batch_tensor = images.permute(0, -1, 1, 2)\n",
    "        grid_img = torchvision.utils.make_grid(images, nrow=50)\n",
    "    \n",
    "        plt.figure(num=None, figsize=(70, 50), dpi=80, facecolor='w', edgecolor='k')\n",
    "        plt.title(title)\n",
    "        plt.grid(b=None)\n",
    "        plt.imshow(grid_img.permute(1, 2, 0))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_filenames = [file for file in [f for f in os.listdir(SHARED_VIDEOS_PATH) if f.endswith('avi') and 'OA790nm' in f]]\n",
    "marked_video_filenames = [os.path.join(SHARED_VIDEOS_PATH, file) for file in video_filenames if 'marked' in file]\n",
    "raw_video_filenames    = [os.path.join(SHARED_VIDEOS_PATH, file) for file in video_filenames if 'marked' not in file]\n",
    "\n",
    "csv_filenames = [os.path.join(SHARED_VIDEOS_PATH, file) for file in [f for f in os.listdir(SHARED_VIDEOS_PATH) if f.endswith('csv') and 'OA790nm' in f]]\n",
    "\n",
    "print(\"BLOOD CELLS\")\n",
    "print(\"-----------\")\n",
    "print(\"RAW VIDEOS:\")\n",
    "print(*marked_video_filenames, sep=\"\\n\")\n",
    "print()\n",
    "\n",
    "print(\"MARKED VIDEOS:\")\n",
    "print(*raw_video_filenames, sep=\"\\n\")\n",
    "print()\n",
    "\n",
    "print(\"CSV FILES:\")\n",
    "print(*csv_filenames, sep=\"\\n\")\n",
    "\n",
    "cone_images_filenames = [os.path.join(SHARED_CONES, file) for file in [f for f in os.listdir(SHARED_CONES) if f.endswith('tif')]]\n",
    "cone_csv_filenames =  [os.path.join(SHARED_CONES, file)for file in [f for f in os.listdir(SHARED_CONES) if f.endswith('txt')]]\n",
    "\n",
    "print()\n",
    "print(\"CONES\")\n",
    "print(\"-----\")\n",
    "print(\"TIFF:\")\n",
    "print(*cone_images_filenames, sep=\"\\n\")\n",
    "print()\n",
    "\n",
    "print(\"CSV:\")\n",
    "print(*cone_csv_filenames, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
    "\n",
    "def get_random_points_in_voronoi_diagram(centroids):\n",
    "    vor = Voronoi(centroids, qhull_options='Qbb Qc Qx', incremental=False)\n",
    "    vor.close()\n",
    "\n",
    "    edges = np.array(vor.ridge_vertices)\n",
    "\n",
    "    edges_start = edges[:, 0]\n",
    "    edges_end = edges[:, 1]\n",
    "\n",
    "    vertices_start = vor.vertices[edges_start]\n",
    "    vertices_end = vor.vertices[edges_end]\n",
    "\n",
    "    t =  np.random.rand(vertices_start.shape[0])\n",
    "   \n",
    "    random_vertices = t[:, np.newaxis] * vertices_start + (1 - t[:, np.newaxis]) * vertices_end\n",
    "    random_vertices = random_vertices[edges_start != -1]\n",
    "\n",
    "    random_vertices = random_vertices[random_vertices[:, 0] >= 0]\n",
    "    random_vertices = random_vertices[random_vertices[:, 0] <= 200]\n",
    "    random_vertices = random_vertices[random_vertices[:, 1] >= 0]\n",
    "    random_vertices = random_vertices[random_vertices[:, 1] <= 200]\n",
    "    \n",
    "    # print(edges_start == -1)\n",
    "    # print(edges_end == -1)\n",
    "    # print(edges_start)\n",
    "    # fig = voronoi_plot_2d(vor)\n",
    "    # plt.imshow(image)\n",
    "    # plt.scatter(random_vertices[:, 0], random_vertices[:, 1], c=\"#FF0000\")\n",
    "    # plt.imshow(image)\n",
    "    return random_vertices\n",
    "\n",
    "#get_random_points_in_voronoi_diagram(positions)\n",
    "# pass\n",
    "# vor.vertices -> the vertices of the voronoi patern.\n",
    "# vor.regions  -> list of list of ints. Indices of the Voronoi vertices forming each Voronoi region. \n",
    "#               The indices refer to vor.vertices.\n",
    "# vor.point_region -> list of ints. Indexes vor.points where it assigns each reagion to a point\n",
    "# vor.ridge_vertices -> Indexes vor.vertices. Each entry shows the two points that form the edge.\n",
    "#                  I.e the edge 5 can have [3, 8] meaning it's formed from vor.vertices[3] -> vor.vertices[8]\n",
    "\n",
    "# np.random.rand(len(vor.ridge_vertices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cone_image_size =(33, 33)\n",
    "cones = np.zeros([0, cone_image_size[0], cone_image_size[1]])\n",
    "non_cones = np.zeros([0, cone_image_size[0], cone_image_size[1]])\n",
    "\n",
    "for image_filename, csv_filename in zip(cone_images_filenames, cone_csv_filenames):\n",
    "    image = plt.imread(image_filename)\n",
    "    positions = np.genfromtxt(csv_filename, delimiter=',')\n",
    "    patches = extract_patches_at_positions(image, \n",
    "                           positions,\n",
    "                           patch_size=cone_image_size,\n",
    "                           visualize_patches=False,\n",
    "                           padding='valid')\n",
    "    non_cone_patches = extract_patches_at_positions(image,\n",
    "                                                    get_random_points_in_voronoi_diagram(positions),\n",
    "                                                    patch_size=cone_image_size,\n",
    "                                                    visualize_patches=False,\n",
    "                                                    padding='valid'\n",
    "                                                   )\n",
    "    \n",
    "    cones = np.append(cones, patches, axis=0)\n",
    "    non_cones = np.append(non_cones, non_cone_patches, axis=0)\n",
    "    \n",
    "    voronoi = Voronoi(positions)\n",
    "    \n",
    "    # no_cone_points = get_random_points_in_voronoi_diagram(positions)\n",
    "    # fig = voronoi_plot_2d(voronoi)\n",
    "    # plt.scatter(no_cone_points[:, 0], no_cone_points[:, 1])\n",
    "    # plt.imshow(image)\n",
    "cones = np.rot90(cones, 2, axes=(1, 2))\n",
    "non_cones = np.rot90(non_cones, 2, axes=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 6, figsize=(20, 10))\n",
    "axes[0, 0].imshow(cones[0], cmap='gray')\n",
    "axes[0, 1].imshow(cones[1], cmap='gray')\n",
    "axes[0, 2].imshow(cones[2], cmap='gray')\n",
    "axes[0, 3].imshow(cones[3], cmap='gray')\n",
    "axes[0, 4].imshow(cones[4], cmap='gray')\n",
    "axes[0, 5].imshow(cones[5], cmap='gray')\n",
    "\n",
    "axes[1, 0].imshow(non_cones[0], cmap='gray')\n",
    "axes[1, 1].imshow(non_cones[1], cmap='gray')\n",
    "axes[1, 2].imshow(non_cones[2], cmap='gray')\n",
    "axes[1, 3].imshow(non_cones[3], cmap='gray')\n",
    "axes[1, 4].imshow(non_cones[4], cmap='gray')\n",
    "axes[1, 5].imshow(non_cones[5], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images_as_grid(cones / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images_as_grid(non_cones / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Cones shape\", cones.shape)\n",
    "print(\"Cones dtype\", cones.dtype)\n",
    "print(\"Non cones shape\", non_cones.shape)\n",
    "print(\"Non cones dtype\", non_cones.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = cones.shape[0]\n",
    "\n",
    "dataset = LabeledImageDataset(\n",
    "        np.concatenate((cones[:n, ...],            non_cones[:n, ...]), axis=0),\n",
    "        np.concatenate((np.ones(n).astype(np.int), np.zeros(n).astype(np.int)), axis=0)\n",
    "    )\n",
    "\n",
    "trainset_size = int(len(dataset) * 0.80)\n",
    "validset_size = len(dataset) - trainset_size\n",
    "\n",
    "trainset, validset = torch.utils.data.random_split(dataset, (trainset_size, validset_size))\n",
    "\n",
    "model = CNN(convolutional=\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(1, 32, padding=2, kernel_size=5),\n",
    "                nn.BatchNorm2d(32),\n",
    "                nn.MaxPool2d(kernel_size=(3, 3), stride=2),\n",
    "                \n",
    "                nn.Conv2d(32, 32, padding=2, kernel_size=5),\n",
    "                nn.BatchNorm2d(32),\n",
    "                nn.ReLU(),\n",
    "                nn.AvgPool2d(kernel_size=3, padding=1, stride=2),\n",
    "                \n",
    "                nn.Conv2d(32, 64, padding=2, kernel_size=5),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(),\n",
    "                nn.AvgPool2d(kernel_size=3, padding=1, stride=2),\n",
    "            ),\n",
    "            dense=\n",
    "            nn.Sequential(\n",
    "                nn.Linear(1024, 64),\n",
    "                nn.BatchNorm1d(64),\n",
    "                nn.ReLU(64),\n",
    "                nn.Linear(64, 32),\n",
    "                nn.BatchNorm1d(32),\n",
    "                nn.Linear(32, 2),\n",
    "             #   nn.Softmax()\n",
    "            )).to(device)\n",
    "\n",
    "params = collections.OrderedDict(\n",
    "    # lr = .001,\n",
    "    #optimizer=torch.optim.SGD(model.parameters(), lr=.001, weight_decay=5e-5, momentum=0.9),\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=.001, weight_decay=5e-4),\n",
    "    batch_size=1024 * 16,\n",
    "    do_early_stop=True,# Optional default True\n",
    "    early_stop_patience=80,\n",
    "    learning_rate_scheduler_patience=100,\n",
    "    epochs=2000,\n",
    "    shuffle=True,\n",
    "    # valid_untrunsformed_normals = valid_untrunsformed_normals,\n",
    "    trainset=trainset,\n",
    "    validset=validset,\n",
    ")\n",
    "\n",
    "results = train(model, params, criterion=torch.nn.CrossEntropyLoss(), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_cone_image = plt.imread(cone_images_filenames[0]).astype(np.float32) / 255\n",
    "plt.imshow(sample_cone_image)\n",
    "results.save(\"cone_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = results.model\n",
    "model = model.eval()\n",
    "\n",
    "probability_map = get_frame_probability_map(sample_cone_image, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blood Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_videos = {}\n",
    "for video in raw_video_filenames:\n",
    "    vidcap = cv2.VideoCapture( SHARED_VIDEOS_PATH + video)\n",
    "\n",
    "    success,image = vidcap.read()\n",
    "    count = 0\n",
    "    while success:\n",
    "        video_key = video[:video.index('nm')]+\"nm\"\n",
    "        raw_videos[video_key] = [image]\n",
    "        success,image = vidcap.read()\n",
    "        count += 1\n",
    "        \n",
    "marked_videos = {}\n",
    "for video in marked_video_filenames:\n",
    "    vidcap = cv2.VideoCapture( SHARED_VIDEOS_PATH + video)\n",
    "\n",
    "    success,image = vidcap.read()\n",
    "    count = 0\n",
    "    while success:\n",
    "        video_key = video[:video.index('nm')]+\"nm\"\n",
    "        marked_videos[video_key] = [image]\n",
    "        success,image = vidcap.read()\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = 19, 19\n",
    "cell_images_1, non_cell_images_1 = get_cell_and_no_cell_patches_from_video(raw_video_filenames[0],\n",
    "                                                                           csv_filenames[0],\n",
    "                                                                           height=height,\n",
    "                                                                           width=width,\n",
    "                                                                           normalise=True,\n",
    "                                                                           )\n",
    "\n",
    "cell_images_2, non_cell_images_2 = get_cell_and_no_cell_patches_from_video(raw_video_filenames[1],\n",
    "                                                                           csv_filenames[1],\n",
    "                                                                           height=height,\n",
    "                                                                           width=width,\n",
    "                                                                           normalise=True,\n",
    "                                                                           )\n",
    "\n",
    "cell_images = np.concatenate((cell_images_1, cell_images_2), axis=0).astype(np.float32)\n",
    "non_cell_images = np.concatenate((non_cell_images_1, non_cell_images_2), axis=0).astype(np.float32)\n",
    "\n",
    "\n",
    "print(cell_images.shape)\n",
    "print(non_cell_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 6, figsize=(20, 10))\n",
    "axes[0, 0].imshow(cell_images[0], cmap='gray')\n",
    "axes[0, 1].imshow(cell_images[1], cmap='gray')\n",
    "axes[0, 2].imshow(cell_images[2], cmap='gray')\n",
    "axes[0, 3].imshow(cell_images[3], cmap='gray')\n",
    "axes[0, 4].imshow(cell_images[4], cmap='gray')\n",
    "axes[0, 5].imshow(cell_images[5], cmap='gray')\n",
    "\n",
    "axes[1, 0].imshow(non_cell_images[0], cmap='gray')\n",
    "axes[1, 1].imshow(non_cell_images[1], cmap='gray')\n",
    "axes[1, 2].imshow(non_cell_images[2], cmap='gray')\n",
    "axes[1, 3].imshow(non_cell_images[3], cmap='gray')\n",
    "axes[1, 4].imshow(non_cell_images[4], cmap='gray')\n",
    "axes[1, 5].imshow(non_cell_images[5], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_images_as_grid(cell_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_images_as_grid(non_cell_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = cell_images.shape[0]\n",
    "\n",
    "dataset = LabeledImageDataset(\n",
    "        np.concatenate((cell_images[:n, ...],      non_cell_images[:n, ...]), axis=0),\n",
    "        np.concatenate((np.ones(n).astype(np.int), np.zeros(n).astype(np.int)), axis=0)\n",
    "    )\n",
    "\n",
    "trainset_size = int(len(dataset) * 0.80)\n",
    "validset_size = len(dataset) - trainset_size\n",
    "\n",
    "trainset, validset = torch.utils.data.random_split(dataset, (trainset_size, validset_size))\n",
    "model = CNN(convolutional=\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(3, 32, padding=2, kernel_size=5),\n",
    "                # PrintLayer(\"1\"),\n",
    "                nn.BatchNorm2d(32),\n",
    "                # PrintLayer(\"2\"),\n",
    "                nn.MaxPool2d(kernel_size=(3, 3), stride=2),\n",
    "                # PrintLayer(\"3\"),\n",
    "\n",
    "                nn.Conv2d(32, 32, padding=2, kernel_size=5),\n",
    "                # PrintLayer(\"4\"),\n",
    "                nn.BatchNorm2d(32),\n",
    "                # PrintLayer(\"5\"),\n",
    "                nn.ReLU(),\n",
    "                # PrintLayer(\"6\"),\n",
    "                nn.AvgPool2d(kernel_size=3, padding=1, stride=2),\n",
    "                # PrintLayer(\"7\"),\n",
    "                \n",
    "                nn.Conv2d(32, 64, padding=2, kernel_size=5),\n",
    "                #PrintLayer(\"9\"),\n",
    "                nn.BatchNorm2d(64),\n",
    "                #PrintLayer(\"11\"),\n",
    "                nn.ReLU(),\n",
    "                nn.AvgPool2d(kernel_size=3, padding=1, stride=2),\n",
    "                # PrintLayer(\"12\"),\n",
    "            ),\n",
    "            dense=\n",
    "            nn.Sequential(\n",
    "                nn.Linear(576, 64),\n",
    "                nn.BatchNorm1d(64),\n",
    "                nn.ReLU(64),\n",
    "                nn.Linear(64, 32),\n",
    "                nn.BatchNorm1d(32),\n",
    "                nn.Linear(32, 2),\n",
    "             #   nn.Softmax()\n",
    "            )).to(device)\n",
    "\n",
    "params = collections.OrderedDict(\n",
    "    # lr = .001,\n",
    "    #optimizer=torch.optim.SGD(model.parameters(), lr=.001, weight_decay=5e-5, momentum=0.9),\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=.001, weight_decay=5e-4),\n",
    "    batch_size=1024 * 16,\n",
    "    do_early_stop=True,# Optional default True\n",
    "    early_stop_patience=80,\n",
    "    learning_rate_scheduler_patience=100,\n",
    "    epochs=2000,\n",
    "    shuffle=True,\n",
    "    # valid_untrunsformed_normals = valid_untrunsformed_normals,\n",
    "    trainset=trainset,\n",
    "    validset=validset,\n",
    ")\n",
    "\n",
    "results = train(model, params,  criterion=torch.nn.CrossEntropyLoss(), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.save(\"cell_trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(images, model, device=\"cuda\"):\n",
    "    \"\"\" Classify images.\n",
    "    \n",
    "    Arguments:\n",
    "        images -- NxHxWxC or NxHxW. The images\n",
    "        model  -- The model to do the prediction\n",
    "    \n",
    "    Returns:\n",
    "        N predictions. A prediction for each image\n",
    "    \"\"\" \n",
    "    if len(images.shape) == 3:\n",
    "        # Add channel dimension if grayscale\n",
    "        images = images[..., None]\n",
    "        \n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        ImageDataset(images),\n",
    "        batch_size=50000,\n",
    "    )\n",
    "    \n",
    "    c = 0\n",
    "    predictions = torch.zeros(images.shape[0])\n",
    "    for batch in loader:\n",
    "        pred = results.model(batch.to(device))\n",
    "        pred = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred = torch.argmax(pred, axis=1)\n",
    "        predictions[c:pred.shape[0]] = pred\n",
    "        \n",
    "        c += pred.shape[0]\n",
    "        \n",
    "    return predictions\n",
    "\n",
    "print(\"Positive accuracy\", classify(cell_images, results.model).sum() / cell_images.shape[0])\n",
    "print(\"Negative accuracy\", 1 - classify(non_cell_images, results.model).sum() / non_cell_images.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(convolutional=\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(3, 32, padding=2, kernel_size=5),\n",
    "                # PrintLayer(\"1\"),\n",
    "                nn.BatchNorm2d(32),\n",
    "                # PrintLayer(\"2\"),\n",
    "                nn.MaxPool2d(kernel_size=(3, 3), stride=2),\n",
    "                # PrintLayer(\"3\"),\n",
    "\n",
    "                nn.Conv2d(32, 32, padding=2, kernel_size=5),\n",
    "                # PrintLayer(\"4\"),\n",
    "                nn.BatchNorm2d(32),\n",
    "                # PrintLayer(\"5\"),\n",
    "                nn.ReLU(),\n",
    "                # PrintLayer(\"6\"),\n",
    "                nn.AvgPool2d(kernel_size=3, padding=1, stride=2),\n",
    "                # PrintLayer(\"7\"),\n",
    "                \n",
    "                nn.Conv2d(32, 64, padding=2, kernel_size=5),\n",
    "                #PrintLayer(\"9\"),\n",
    "                nn.BatchNorm2d(64),\n",
    "                #PrintLayer(\"11\"),\n",
    "                nn.ReLU(),\n",
    "                nn.AvgPool2d(kernel_size=3, padding=1, stride=2),\n",
    "                # PrintLayer(\"12\"),\n",
    "            ),\n",
    "            dense=\n",
    "            nn.Sequential(\n",
    "                nn.Linear(576, 64),\n",
    "                nn.BatchNorm1d(64),\n",
    "                nn.ReLU(64),\n",
    "                nn.Linear(64, 32),\n",
    "                nn.BatchNorm1d(32),\n",
    "                nn.Linear(32, 2),\n",
    "             #   nn.Softmax()\n",
    "            )).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('cell_trained.pt'))\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = 19, 19\n",
    "\n",
    "frames = get_frames_from_video(raw_video_filenames[0])\n",
    "print(frames.dtype)\n",
    "sample_frame = frames[0, ...]\n",
    "plt.imshow(sample_frame)\n",
    "\n",
    "probability_map = get_frame_probability_map(sample_frame, model, height=height, width=width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(probability_map > 0.5,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_map > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}