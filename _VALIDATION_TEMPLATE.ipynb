{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 30\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from plotutils import plot_images_as_grid\n",
    "\n",
    "from imageprosessing import hist_match_images, enhance_motion_contrast, normalize_data\n",
    "from sharedvariables import get_video_sessions\n",
    "from video_session import VideoSession\n",
    "from imageprosessing import SessionPreprocessor\n",
    "from classificationutils import SessionClassifier\n",
    "from patchextraction import SessionPatchExtractor\n",
    "from patchextraction import SessionPatchExtractor as PE\n",
    "from cnnlearning import CNN\n",
    "\n",
    "from learningutils import ImageDataset\n",
    "from classificationutils import create_probability_map\n",
    "from plotutils import *\n",
    "from cnnlearning import TrainingTracker, train\n",
    "import os\n",
    "import collections\n",
    "import pathlib\n",
    "\n",
    "import scipy\n",
    "import skimage\n",
    "from skimage.morphology import binary_dilation as bd\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import cv2\n",
    "import copy\n",
    "\n",
    "from tqdm.contrib import tzip\n",
    "\n",
    "from patchextraction import extract_patches\n",
    "from patchextraction import SessionPatchExtractor as PE\n",
    "from imageprosessing import ImageRegistrator\n",
    "from collections import OrderedDict\n",
    "\n",
    "# change this\n",
    "result_folder_name = 'uid0-sc-npp32-tp2-ps17-mt0-pr0-uv1'\n",
    "\n",
    "# change this\n",
    "classifier_params = collections.OrderedDict(        \n",
    "    patch_size=17,\n",
    "    \n",
    "    mixed_channels=False,\n",
    "    drop_confocal=False,\n",
    "\n",
    "    n_negatives_per_positive=32,\n",
    "    negative_extraction_mode=SessionPatchExtractor.CIRCLE,                             \n",
    "    use_vessel_mask=True\n",
    ")\n",
    "\n",
    "## ## ## ## ##\n",
    "report_images_folder = os.path.join(\n",
    "    '..', '..', 'thesis-report', 'images', result_folder_name,\n",
    ")\n",
    "pathlib.Path(report_images_folder).mkdir(exist_ok=True, parents=False)\n",
    "\n",
    "print()\n",
    "results = TrainingTracker.from_file(os.path.join('tmp-res', result_folder_name, 'results.pkl'))\n",
    "print('Training results loaded')\n",
    "\n",
    "recorded_models_props = results.recorded_models['best_valid_balanced_accuracy']\n",
    "model =  recorded_models_props['model'].eval()\n",
    "\n",
    "print()\n",
    "print('Model validation performance\\n',  recorded_models_props['valid_classification_results'])\n",
    "print()\n",
    "\n",
    "video_sessions = get_video_sessions(marked=True, registered=False, validation=True)\n",
    "print('loaded validation Video sessions:', len(video_sessions))\n",
    "[vs.basename for vs in video_sessions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load validation videos and make sure vessel masks are ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_video_sessions = get_video_sessions(marked=True, validation=True)\n",
    "\n",
    "[vs.load_vessel_masks(False) for vs in validation_video_sessions]\n",
    "[vs.basename for vs in validation_video_sessions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vs in validation_video_sessions:\n",
    "    vs.visualize_registration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on patch classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_recorded_model_props = results.recorded_models['best_valid_balanced_accuracy']\n",
    "model = valid_recorded_model_props['model'].eval()\n",
    "\n",
    "classification_results = valid_recorded_model_props['valid_classification_results']\n",
    "\n",
    "sensitivities = []\n",
    "specificities = []\n",
    "balanced_accuracies  = []\n",
    "accuracies = []\n",
    "\n",
    "print('General validation performance\\n', classification_results)\n",
    "for vs in validation_video_sessions:\n",
    "    vs_c = SessionClassifier(vs, model, **classifier_params)\n",
    "    classification_results = vs_c.classify_cells()\n",
    "    \n",
    "    sensitivity = classification_results.positive_accuracy\n",
    "    specificity = classification_results.negative_accuracy\n",
    "    balanced_accuracy = classification_results.balanced_accuracy\n",
    "    accuracy = classification_results.accuracy\n",
    "    \n",
    "    sensitivities.append(sensitivity)\n",
    "    specificities.append(specificity)\n",
    "    balanced_accuracies.append(balanced_accuracy)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "    print(vs.basename)\n",
    "    print(f'Sensitivity: {sensitivity:.3f}', \n",
    "          f'Specificity: {specificity:.3f}',\n",
    "          f'Balanced acc: {balanced_accuracy:.3f}',\n",
    "          f'accuracy: {accuracy:.3f}', sep='\\n')\n",
    "    print('-----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_sensitivity = np.mean(sensitivities)\n",
    "test_specificity = np.mean(specificities)\n",
    "test_balanced_accuracy = np.mean(balanced_accuracies)\n",
    "test_accuracy = np.mean(accuracies)\n",
    "\n",
    "performance_data = {\n",
    "    'Balanced accuracy': test_balanced_accuracy,\n",
    "    'Accuracy': test_accuracy,\n",
    "    'Sensitivity': test_sensitivity,\n",
    "    'Specificity': test_specificity\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(performance_data, columns=list(performance_data.keys()), index=[0])\n",
    "print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = video_sessions[0]\n",
    "frame_idx = list(vs.cell_positions.keys())[-1]\n",
    "\n",
    "positions = vs.cell_positions[frame_idx]\n",
    "masked_frame = vs.frames_oa790[frame_idx] * vs.vessel_mask_oa790 * vs.mask_frames_oa790[frame_idx]\n",
    "\n",
    "### plots #### \n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.figure(figsize=(10, 10))\n",
    "no_ticks()\n",
    "plt.imshow(masked_frame)\n",
    "plt.scatter(positions[:, 0], positions[:, 1], s=25)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from guitools import CvRoipolySelector\n",
    "# vessel_mask_clone = np.uint8(vs.vessel_mask_oa790.copy() * 255)\n",
    "# vessel_mask_clone = vessel_mask_clone[..., np.newaxis]\n",
    "# vessel_mask_clone = np.concatenate((vessel_mask_clone, vessel_mask_clone, vessel_mask_clone), axis=-1)\n",
    "\n",
    "# # for positions in vs.cell_positions.values():\n",
    "# for (x, y) in positions:\n",
    "#     vessel_mask_clone = cv2.circle(vessel_mask_clone, (x, y), 5, (255, 0, 0), -1)\n",
    "\n",
    "# polyselector = CvRoipolySelector('Select part to remove', vessel_mask_clone)\n",
    "# polyselector.activate()\n",
    "# plt.figure(figsize=(25, 10))\n",
    "# no_ticks()\n",
    "# plt.imshow(vessel_mask_clone[..., -1] * ~polyselector.mask)\n",
    "\n",
    "# vs.vessel_mask_oa790[polyselector.mask] = 0\n",
    "# plt.figure(figsize=(25, 10))\n",
    "# no_ticks()\n",
    "# plt.imshow(vs.vessel_mask_oa790)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_c = SessionClassifier(vs, model, **classifier_params)\n",
    "estimated_locations = vs_c.estimate_locations(frame_idx, grid_search=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.titlesize'] = 50\n",
    "vs_c.result_evaluations[frame_idx].visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vs_c.save(os.path.join(result_evaluation_folder, f'uid{vs.uid}_classification_results.pkl'), v=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_c = SessionClassifier(vs, model, **classifier_params)\n",
    "\n",
    "for frame_idx in vs.cell_positions:\n",
    "    estimated_locations = vs_c.estimate_locations(frame_idx, grid_search=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dices = [evaluation.dice for evaluation in vs_c.result_evaluations.values()]\n",
    "false_discovery_rates = [evaluation.false_discovery_rate for evaluation in vs_c.result_evaluations.values()]\n",
    "true_positive_rates = [evaluation.true_positive_rate for evaluation in vs_c.result_evaluations.values()]\n",
    "\n",
    "mean_dice = np.mean(dices)\n",
    "mean_false_discovery_rates = np.mean(false_discovery_rates)\n",
    "mean_true_positive_rates = np.mean(true_positive_rates)\n",
    "\n",
    "mean_dice, mean_false_discovery_rates, mean_true_positive_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas = [evaluation.sigma for evaluation in vs_c.result_evaluations.values()]\n",
    "hs = [evaluation.extended_maxima_h for evaluation in vs_c.result_evaluations.values()]\n",
    "ts = [evaluation.region_max_threshold for evaluation in vs_c.result_evaluations.values()]\n",
    "\n",
    "mean_sigma = np.mean(sigmas)\n",
    "mean_h = np.mean(hs)\n",
    "mean_t = np.mean(ts)\n",
    "\n",
    "mean_sigma, mean_h, mean_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_to_s = {416: 1.833333333333334, 429: 1.3000000000000003, 980: 1.5777777777777784}\n",
    "uid_to_h = {416: 0.3833333333333333, 429: 0.30000000000000004, 980: 0.3333333333333333}\n",
    "uid_to_t = {416: 0.6166666666666668, 429: 0.5750000000000001, 980: 0.588888888888889}\n",
    "\n",
    "session_classifiers = []\n",
    "for vs in validation_video_sessions:\n",
    "    print('-----------')\n",
    "    print(vs.basename)\n",
    "    \n",
    "    vsc = SessionClassifier(vs, model, **classifier_params)\n",
    "    session_classifiers.append(vsc)\n",
    "    \n",
    "    print('Estimating positions...')\n",
    "    for frame_idx in vs.cell_positions:\n",
    "        vsc.estimate_locations(\n",
    "            frame_idx, grid_search=True\n",
    "        )\n",
    "\n",
    "    vsc.save(os.path.join(result_evaluation_folder, f'uid{vs.uid}_classification_results.pkl'), v=True)\n",
    "    \n",
    "    sigmas = [evaluation.sigma for evaluation in vsc.result_evaluations.values()]\n",
    "    hs = [evaluation.extended_maxima_h for evaluation in vsc.result_evaluations.values()]\n",
    "    ts = [evaluation.region_max_threshold for evaluation in vsc.result_evaluations.values()]\n",
    "    \n",
    "    dices = [evaluation.dice for evaluation in vsc.result_evaluations.values()]\n",
    "    false_discovery_rates = [evaluation.false_discovery_rate for evaluation in vsc.result_evaluations.values()]\n",
    "    true_positive_rates = [evaluation.true_positive_rate for evaluation in vsc.result_evaluations.values()]\n",
    "    \n",
    "\n",
    "    print(f'Dice: {np.mean(dices):.3f}', \n",
    "          f'False discovery rate: {np.mean(false_discovery_rates):.3f}',\n",
    "          f'True positive rate: {np.mean(true_positive_rates):.3f}', sep='\\n')\n",
    "    print('-----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_to_sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dices = []\n",
    "all_false_discovery_rates = []\n",
    "all_true_positive_rates = []\n",
    "\n",
    "all_sigmas = []\n",
    "all_hs = []\n",
    "all_ts = []\n",
    "\n",
    "uid_to_sigmas = {}\n",
    "uid_to_hs = {}\n",
    "uid_to_ts = {}\n",
    "\n",
    "uid_to_s = {}\n",
    "uid_to_h = {}\n",
    "uid_to_t = {}\n",
    "\n",
    "for vsc in session_classifiers:\n",
    "    sigmas = [evaluation.sigma for evaluation in vsc.result_evaluations.values()]\n",
    "    hs = [evaluation.extended_maxima_h for evaluation in vsc.result_evaluations.values()]\n",
    "    ts = [evaluation.region_max_threshold for evaluation in vsc.result_evaluations.values()]\n",
    "    \n",
    "    dices = [evaluation.dice for evaluation in vsc.result_evaluations.values()]\n",
    "    false_discovery_rates = [evaluation.false_discovery_rate for evaluation in vsc.result_evaluations.values()]\n",
    "    true_positive_rates = [evaluation.true_positive_rate for evaluation in vsc.result_evaluations.values()]\n",
    "    \n",
    "    print(vsc.session.uid)\n",
    "    uid_to_sigmas[vsc.session.uid] =  sigmas\n",
    "    uid_to_hs[vsc.session.uid] = hs\n",
    "    uid_to_ts[vsc.session.uid] = ts\n",
    "    \n",
    "    uid_to_s[vsc.session.uid] = np.mean(sigmas)\n",
    "    uid_to_h[vsc.session.uid] = np.mean(hs)\n",
    "    uid_to_t[vsc.session.uid] = np.mean(ts)\n",
    "    \n",
    "    all_sigmas.extend(sigmas)\n",
    "    all_hs.extend(hs)\n",
    "    all_ts.extend(ts)\n",
    "    \n",
    "    all_dices.extend(dices)\n",
    "    all_false_discovery_rates.extend(false_discovery_rates)\n",
    "    all_true_positive_rates.extend(true_positive_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(all_dices), np.mean(all_false_discovery_rates), np.mean(all_true_positive_rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load session classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_session_classifiers = []\n",
    "\n",
    "# Load session_classifiers\n",
    "for vs in validation_video_sessions:\n",
    "    vsc = SessionClassifier.from_file(\n",
    "        os.path.join(result_evaluation_folder, f'uid{vs.uid}_classification_results.pkl'), v=False)\n",
    "    loaded_session_classifiers.append(vsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dices = []\n",
    "all_false_discovery_rates = []\n",
    "all_true_positive_rates = []\n",
    "\n",
    "for vsc in loaded_session_classifiers:\n",
    "    sigmas = [evaluation.sigma for evaluation in vsc.result_evaluations.values()]\n",
    "    hs = [evaluation.extended_maxima_h for evaluation in vsc.result_evaluations.values()]\n",
    "    ts = [evaluation.region_max_threshold for evaluation in vsc.result_evaluations.values()]\n",
    "    \n",
    "    dices = [evaluation.dice for evaluation in vsc.result_evaluations.values()]\n",
    "    false_discovery_rates = [evaluation.false_discovery_rate for evaluation in vsc.result_evaluations.values()]\n",
    "    true_positive_rates = [evaluation.true_positive_rate for evaluation in vsc.result_evaluations.values()]\n",
    "    \n",
    "    all_dices.extend(dices)\n",
    "    all_false_discovery_rates.extend(false_discovery_rates)\n",
    "    all_true_positive_rates.extend(true_positive_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(all_dices), np.mean(all_false_discovery_rates), np.mean(all_true_positive_rates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
